{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install plotly\n",
    "!pip install autoviz\n",
    "!pip install dataprep\n",
    "!pip install ydata-profiling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fIPMM37lhSS8",
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TSlyA6zpVNei",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "FeL1Ukamg_BR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating train and test data sets (from GitHub, no need to add it manually)\n",
    "url = 'https://raw.githubusercontent.com/AnastasiaDv491/AA-datasets/main/train.csv'\n",
    "\n",
    "full_data_set = pd.read_csv(url)\n",
    "\n",
    "target_price = full_data_set['target']\n",
    "feature_full = full_data_set.drop('target', axis=1)\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(feature_full, target_price, random_state=1)\n",
    "\n",
    "matrix_train = feature_train.join(target_train,on=\"property_id\")\n",
    "#test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK5pijjxhQ3M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "full_data_set.head()\n",
    "full_data_set.tail()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0SLjt5KOjT0n",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis (EDA) (DO NOT RUN, VERY SLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5y1sqJ1di_Qr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_data_set.shape     ##(6495, 55)\n",
    "\n",
    "## looking at a few measures\n",
    "\n",
    "full_data_set.describe()\n",
    "\n",
    "full_data_set.nunique()\n",
    "\n",
    "full_data_set['host_response_time'].unique()\n",
    "\n",
    "full_data_set.isnull().sum()  ## quite a few variables can be dropped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYvFc1WQjtHy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## variables that need to be dropped, shall be commented out below\n",
    "\n",
    "df = full_data_set[['property_id', 'property_name', 'property_summary', 'property_space',\n",
    "       'property_desc', 'property_neighborhood', 'property_notes',\n",
    "       'property_transit', 'property_access', 'property_interaction',\n",
    "       'property_rules', 'property_zipcode', 'property_lat', 'property_lon',\n",
    "       'property_type', 'property_room_type', 'property_max_guests',\n",
    "       'property_bathrooms', 'property_bedrooms', 'property_beds',\n",
    "       'property_bed_type', 'property_amenities', 'property_sqfeet',\n",
    "       'property_scraped_at', 'property_last_updated', 'host_id', 'host_since',\n",
    "       'host_location', 'host_about', 'host_response_time',\n",
    "       'host_response_rate', 'host_nr_listings', 'host_nr_listings_total',\n",
    "       'host_verified', 'booking_price_covers', 'booking_min_nights',\n",
    "       'booking_max_nights', 'booking_availability_30',\n",
    "       'booking_availability_60', 'booking_availability_90',\n",
    "       'booking_availability_365', 'booking_cancel_policy', 'reviews_num',\n",
    "       'reviews_first', 'reviews_last', 'reviews_rating', 'reviews_acc',\n",
    "       'reviews_cleanliness', 'reviews_checkin', 'reviews_communication',\n",
    "       'reviews_location', 'reviews_value', 'reviews_per_month', 'extra',\n",
    "       'target']].copy()\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "Qi0K1ZgMmELB",
    "outputId": "155e9af8-a4a4-4ffb-ed69-0c4eb80fe181",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Relationship analysis\n",
    "\n",
    "correlation = df.corr()\n",
    "sns.heatmap(correlation, xticklabels=correlation.columns, yticklabels=correlation.columns, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dw3iBowfnY8C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg_i7_avknlM"
   },
   "source": [
    "From here on we will proceed with only the train features in order to avoid any data spillage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xgUpG0dDprFf"
   },
   "source": [
    "## Autoviz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3wg3Rm-Dz1wZ"
   },
   "source": [
    "[Documentation](https://www.kaggle.com/general/233832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wI-7M-09jXdF",
    "outputId": "ebc64b01-4b12-46eb-c9ad-1c30d7529368",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing Autoviz class\n",
    "from autoviz.AutoViz_Class import AutoViz_Class #Instantiate the AutoViz class\n",
    "AV = AutoViz_Class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5eUbWA4yldoD",
    "outputId": "e32c19f0-8f9b-4fc9-93aa-444ed774549b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda=AV.AutoViz(filename=\"\",dfte=matrix_train, chart_format='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_feature_train = AV.AutoViz(filename=\"\",dfte=feature_train, chart_format='html')\n",
    "eda_feature_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_target_train = AV.AutoViz(filename=\"\",dfte=target_train, chart_format='html')\n",
    "eda_target_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA using DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import create_report\n",
    "\n",
    "target_report = create_report(target_train)\n",
    "target_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_report.show_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_report = create_report(feature_train)\n",
    "feature_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_report.show_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_report = create_report(matrix_train)\n",
    "matrix_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_report.show_browser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "egMFmRx5q4B8"
   },
   "source": [
    "## Ydata-profling (Former pandas-profling)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7i9dwPcWz-ZA"
   },
   "source": [
    "[Documentation](https://ydata-profiling.ydata.ai/docs/master/pages/getting_started/quickstart.html#using-inside-jupyter-notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ldRGMcTrB9t",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Al0RjOtyrfy1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile = ProfileReport(matrix_train,title=\"Pandas Profiling Report\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sRAyswxMsBs4"
   },
   "source": [
    "### Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "cXLFMgiZsIHL",
    "outputId": "2d4701a7-88bf-4127-d7d2-2dc9611e8a25",
    "tags": []
   },
   "outputs": [],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp48PExAsGGx"
   },
   "source": [
    "### HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "8UK9kt5vzHu1",
    "outputId": "969d657b-1891-4bdf-e3ae-8cdb1db4c4ee"
   },
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()\n",
    "profile.to_file(\"Ydata_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "eh9BzwdX34oX",
    "outputId": "42d065c1-6aad-4a44-8381-0a7a8ecac9c1"
   },
   "outputs": [],
   "source": [
    "profile.to_file(\"Ydata_report.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uwkSiCcghMhv",
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Puz6mw2NRBz7",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pipeline for feature processing (unused)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only figured out how to use pipelines too late into project\n",
    "Decided to just use old, less efficient way instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = feature_train.copy()\n",
    "\n",
    "non_numeric_cols= ['property_type',\n",
    " 'property_room_type',\n",
    " 'property_bed_type',\n",
    " 'host_response_time',\n",
    " 'booking_cancel_policy',\n",
    " 'reviews_first',\n",
    " 'reviews_last',\n",
    " 'property_last_updated_bucket',\n",
    " 'host_nr_listings_cat',\n",
    " 'property_bathrooms_cat',\n",
    " 'propety_beds_cat',\n",
    " 'property_bedrooms_cat',\n",
    " 'reviews_cleanliness_n',\n",
    " 'reviews_checkin_n',\n",
    " 'reviews_location_n',\n",
    " 'reviews_communication_n',\n",
    " 'reviews_value_n']\n",
    "\n",
    "def isMissing(df, col, new_col):\n",
    "  df[new_col] = np.where(df[col].isna(), 1, 0)\n",
    "  return df\n",
    "\n",
    "\n",
    "class toLowerCase():\n",
    "  def __init__(self, columns=None):\n",
    "    self.columns = columns\n",
    "    \n",
    "  def fit(self, X, y=None):\n",
    "      return self\n",
    "  \n",
    "  def transform(self,X, y= None):\n",
    "    X = X.apply(lambda x: x.str.lower() if x.dtype=='object' else x)\n",
    "\n",
    "    return X\n",
    "\n",
    "def SummaryMissing(df, col, new_col):\n",
    "  df[new_col] = np.where(df[col].str.split().str.len() == 1, 1, 0)\n",
    "  df[new_col] = np.where(df[col].isna(), 1, 0)   \n",
    "  return df\n",
    "  \n",
    "def splitCountWords(df, cols):\n",
    "  for col in cols:\n",
    "    df[col] = df[col].str.replace('\\d+', '').replace('[^\\w\\s]',' ')\n",
    "    df[col] = df[col].str.split().str.len()\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "  return df\n",
    "\n",
    "def columnDropperTransformer(df, cols):\n",
    "  df = df.drop(cols, axis=1)\n",
    "  return df\n",
    "    \n",
    "def featureGrouping(df, col):\n",
    "  threshold_percent = 3\n",
    "\n",
    "  series = pd.value_counts(df['property_type'])\n",
    "  mask = (series / series.sum() * 100).lt(threshold_percent)\n",
    "\n",
    "  df= df.assign(col = np.where(df[col].isin(series[mask].index),'Other', df[col]))\n",
    "  return df \n",
    "\n",
    "def replaceWithMode(df, cols):\n",
    "  for col in cols:\n",
    "      df[col]= df[col].fillna(df[col].mode()[0])\n",
    "  return df\n",
    "\n",
    "def replacewithZero(df, cols):\n",
    "  for col in cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "  return df\n",
    "\n",
    "def removeSpaces(df, cols):\n",
    "  for col in cols:\n",
    "    df[col] = df[col].replace(' ', '')\n",
    "  return df\n",
    "\n",
    "def BathroomsCount(df, col,new_col):\n",
    "  df[new_col]= 'One'\n",
    "  df.loc[(df[col] < 1) , new_col] = 'None'\n",
    "  df.loc[(df[col] > 1), new_col] = 'More than one'\n",
    "\n",
    "  df = df.drop([col], axis = 1)\n",
    "  return df\n",
    "\n",
    "def NumToCategory(df, cols,new_cols):\n",
    "  for col, new_col in zip(cols, new_cols):\n",
    "    conditions = [\n",
    "      (df[col]==1),\n",
    "      (df[col]==2),\n",
    "      (df[col]==3),\n",
    "      (df[col]>3)\n",
    "    ]\n",
    "    choices = ['One', 'Two', 'Three', 'More than three']\n",
    "    df[new_col] = np.select(conditions, choices) \n",
    "  return df\n",
    "\n",
    "def reviewRecoding(df, cols, new_cols):\n",
    "  for col, new_col in zip(cols, new_cols):\n",
    "    df[new_col] = df[col].fillna(\"Average\") # average\n",
    "    df.loc[(df[col] == 5) , new_col] = 'Average'\n",
    "\n",
    "    df.loc[(df[col] < 5) , new_col] = 'Bad'\n",
    "    df.loc[(df[col] > 5), new_col] = 'Good'\n",
    "    df = df.drop([col], axis = 1)\n",
    "  return df\n",
    "\n",
    "def change_datetime_format(df,cols):\n",
    "  for col in cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "  return df\n",
    "\n",
    "def add_scrapped_weekday(df,cols,new_cols):\n",
    "  df[new_cols] = df[cols].dt.weekday\n",
    "  return df\n",
    "\n",
    "def last_updated_wrap(df,col,new_col):\n",
    "  def last_updated_conversion(update_var:str):\n",
    "    # 3 Buckets evenly distributed based on train, 2 for > 3 months, 0 for updated yesterday/today\n",
    "    if \"never\" in update_var:\n",
    "      return \"3 months or more\"\n",
    "    elif \"month\" in update_var:\n",
    "      if int(update_var.split(\" \")[0])>=3:\n",
    "        return \"3 months or more\"\n",
    "      else:\n",
    "        return \"1 week to 3 months\"\n",
    "    elif \"week\" in update_var:\n",
    "      return \"1 week to 3 months\"\n",
    "    else: # This catches yesterday etc. is actually equivalent to \"day\" in update_var\n",
    "      return \"Within days\"\n",
    "  df[new_col] = [last_updated_conversion(x) for x in df[col]] \n",
    "  df = df.drop([col], axis = 1) # Dropping old column\n",
    "  return df\n",
    "\n",
    "def splitOnComma(df, col):\n",
    "  df[col] =  df[col].str.split(', ').str.len()\n",
    "  return df\n",
    "\n",
    "# #TODO: you have to include those columns as arguments you pass to the function. then you pass teh original names of the cols to the function transformer\n",
    "\n",
    "def host_since_transform(df,col):\n",
    "  df[col] = df[col].fillna(df[col].mean()) # Simply imputing with mean, only had 1 NA anyways\n",
    "  df['host_since_scraped'] = df['property_scraped_at']-df['host_since']\n",
    "  df['host_since_scraped'] = df['host_since_scraped'].dt.days.astype('int16')\n",
    "  df = df.drop(['host_since'], axis = 1) # Dropping old columns\n",
    "  return df \n",
    "\n",
    "def missing_cat(df,col):\n",
    "  # Just adds \"Missing\" as categorical value\n",
    "  df[col].fillna(value=\"Missing\",inplace=True)\n",
    "  return df\n",
    "\n",
    "def missing_to_100(df,col):\n",
    "  df[col]=df[col].fillna(value=100)\n",
    "  return df\n",
    "\n",
    "def listing_number_transform(df,col,new_col):\n",
    "  df.loc[(df[col] <= 1) , new_col] = 'One or less'\n",
    "  df.loc[(df[col].isna()) , new_col] = 'One or less'\n",
    "  df.loc[(df[col] > 1) & (df[col] <=3), new_col] = 'Two to Three'\n",
    "  df.loc[(df[col] > 3), new_col] = 'More than 3'\n",
    "\n",
    "  df = df.drop([col], axis = 1)\n",
    "  return df \n",
    "\n",
    "def min_nights_transform(df,col):\n",
    "  df = df[df[col]<30]\n",
    "  return df\n",
    "\n",
    "def max_nights_transform(df,col):\n",
    "  df.loc[df[col] >60, col] = 60\n",
    "  return df\n",
    "\n",
    "def booking_availability_transform(df,col):\n",
    "  df[col] = df[col]-df['booking_availability_90']\n",
    "  df['booking_availability_90'] = df['booking_availability_90'] - df['booking_availability_60']\n",
    "  df['booking_availability_60'] = df['booking_availability_60']- df['booking_availability_30']\n",
    "  return df\n",
    "\n",
    "def one_hot_func(df,col):\n",
    "  dummie_cols = pd.get_dummies(df[col])\n",
    "  df = pd.concat([df,dummie_cols], axis=1)\n",
    "  df = df.drop(col, axis=1)\n",
    "  return df \n",
    "\n",
    "def zip_func(df,col):\n",
    "  df[col] = df[col].replace(' ','')\n",
    "  dummies = pd.get_dummies(df[col])\n",
    "  sorted_dummies = dummies[dummies.sum().sort_values(ascending=False).index]\n",
    "  df = pd.concat([df,sorted_dummies.iloc[:,:10]],axis=1)\n",
    "  df = df.drop(col, axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svnel\\AppData\\Local\\Temp\\ipykernel_15072\\784169939.py:50: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[col] = df[col].str.replace('\\d+', '').replace('[^\\w\\s]',' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_name</th>\n",
       "      <th>property_summary</th>\n",
       "      <th>property_max_guests</th>\n",
       "      <th>property_bedrooms</th>\n",
       "      <th>property_beds</th>\n",
       "      <th>property_amenities</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_verified</th>\n",
       "      <th>booking_price_covers</th>\n",
       "      <th>booking_min_nights</th>\n",
       "      <th>booking_max_nights</th>\n",
       "      <th>booking_availability_30</th>\n",
       "      <th>booking_availability_60</th>\n",
       "      <th>booking_availability_90</th>\n",
       "      <th>booking_availability_365</th>\n",
       "      <th>reviews_num</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_acc</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>property_summary_miss</th>\n",
       "      <th>scraped_weekday</th>\n",
       "      <th>property_name_miss</th>\n",
       "      <th>host_since_scraped</th>\n",
       "      <th>property_type_apartment</th>\n",
       "      <th>property_type_bed &amp; breakfast</th>\n",
       "      <th>property_type_boat</th>\n",
       "      <th>property_type_boutique hotel</th>\n",
       "      <th>property_type_cabin</th>\n",
       "      <th>property_type_camper/rv</th>\n",
       "      <th>property_type_castle</th>\n",
       "      <th>property_type_chalet</th>\n",
       "      <th>property_type_condominium</th>\n",
       "      <th>property_type_dorm</th>\n",
       "      <th>property_type_guest suite</th>\n",
       "      <th>property_type_guesthouse</th>\n",
       "      <th>property_type_hostel</th>\n",
       "      <th>property_type_house</th>\n",
       "      <th>property_type_loft</th>\n",
       "      <th>property_type_other</th>\n",
       "      <th>property_type_serviced apartment</th>\n",
       "      <th>property_type_townhouse</th>\n",
       "      <th>property_type_villa</th>\n",
       "      <th>property_type_yurt</th>\n",
       "      <th>property_room_type_entire home/apt</th>\n",
       "      <th>property_room_type_private room</th>\n",
       "      <th>property_room_type_shared room</th>\n",
       "      <th>property_bed_type_airbed</th>\n",
       "      <th>property_bed_type_couch</th>\n",
       "      <th>property_bed_type_futon</th>\n",
       "      <th>property_bed_type_pull-out sofa</th>\n",
       "      <th>property_bed_type_real bed</th>\n",
       "      <th>host_response_time_a few days or more</th>\n",
       "      <th>host_response_time_missing</th>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <th>booking_cancel_policy_flexible</th>\n",
       "      <th>booking_cancel_policy_moderate</th>\n",
       "      <th>booking_cancel_policy_strict</th>\n",
       "      <th>booking_cancel_policy_super_strict_30</th>\n",
       "      <th>property_last_updated_bucket_1 week to 3 months</th>\n",
       "      <th>property_last_updated_bucket_3 months or more</th>\n",
       "      <th>property_last_updated_bucket_within days</th>\n",
       "      <th>host_nr_listings_cat_more than 3</th>\n",
       "      <th>host_nr_listings_cat_one or less</th>\n",
       "      <th>host_nr_listings_cat_two to three</th>\n",
       "      <th>property_bathrooms_cat_More than one</th>\n",
       "      <th>property_bathrooms_cat_None</th>\n",
       "      <th>property_bathrooms_cat_One</th>\n",
       "      <th>propety_beds_cat_0</th>\n",
       "      <th>propety_beds_cat_More than three</th>\n",
       "      <th>propety_beds_cat_One</th>\n",
       "      <th>propety_beds_cat_Three</th>\n",
       "      <th>propety_beds_cat_Two</th>\n",
       "      <th>property_bedrooms_cat_0</th>\n",
       "      <th>property_bedrooms_cat_More than three</th>\n",
       "      <th>property_bedrooms_cat_One</th>\n",
       "      <th>property_bedrooms_cat_Three</th>\n",
       "      <th>property_bedrooms_cat_Two</th>\n",
       "      <th>reviews_cleanliness_n_Average</th>\n",
       "      <th>reviews_cleanliness_n_Bad</th>\n",
       "      <th>reviews_cleanliness_n_Good</th>\n",
       "      <th>reviews_checkin_n_Average</th>\n",
       "      <th>reviews_checkin_n_Bad</th>\n",
       "      <th>reviews_checkin_n_Good</th>\n",
       "      <th>reviews_location_n_Average</th>\n",
       "      <th>reviews_location_n_Bad</th>\n",
       "      <th>reviews_location_n_Good</th>\n",
       "      <th>reviews_communication_n_Average</th>\n",
       "      <th>reviews_communication_n_Bad</th>\n",
       "      <th>reviews_communication_n_Good</th>\n",
       "      <th>reviews_value_n_Average</th>\n",
       "      <th>reviews_value_n_Bad</th>\n",
       "      <th>reviews_value_n_Good</th>\n",
       "      <th>1000</th>\n",
       "      <th>1050</th>\n",
       "      <th>1060</th>\n",
       "      <th>2000</th>\n",
       "      <th>1030</th>\n",
       "      <th>1040</th>\n",
       "      <th>1190</th>\n",
       "      <th>2018</th>\n",
       "      <th>1180</th>\n",
       "      <th>1070</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>275</td>\n",
       "      <td>5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>272</td>\n",
       "      <td>128</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1546</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4808 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      property_name  property_summary  property_max_guests  property_bedrooms  \\\n",
       "4337           10.0              40.0                    2                1.0   \n",
       "3473            2.0              38.0                    2                1.0   \n",
       "6133            5.0               0.0                    2                1.0   \n",
       "40              5.0              32.0                    2                1.0   \n",
       "3499            4.0              56.0                    2                0.0   \n",
       "...             ...               ...                  ...                ...   \n",
       "905             7.0              38.0                    2                1.0   \n",
       "5192            5.0              46.0                    2                0.0   \n",
       "3980            4.0              39.0                    5                0.0   \n",
       "235             5.0              40.0                    1                1.0   \n",
       "5157            3.0              31.0                    3                1.0   \n",
       "\n",
       "      property_beds  property_amenities  host_response_rate  host_verified  \\\n",
       "4337            1.0                12.0                67.0              6   \n",
       "3473            2.0                15.0               100.0              4   \n",
       "6133            1.0                 9.0                50.0              4   \n",
       "40              1.0                11.0               100.0              4   \n",
       "3499            1.0                14.0               100.0              3   \n",
       "...             ...                 ...                 ...            ...   \n",
       "905             1.0                14.0               100.0              2   \n",
       "5192            2.0                18.0               100.0              4   \n",
       "3980            3.0                 8.0               100.0              2   \n",
       "235             1.0                 8.0               100.0              2   \n",
       "5157            1.0                14.0                98.0              4   \n",
       "\n",
       "      booking_price_covers  booking_min_nights  booking_max_nights  \\\n",
       "4337                     1                   1                  60   \n",
       "3473                     1                   2                  60   \n",
       "6133                     1                   1                  60   \n",
       "40                       2                   2                  60   \n",
       "3499                     1                   1                  60   \n",
       "...                    ...                 ...                 ...   \n",
       "905                      1                   2                  60   \n",
       "5192                     2                  15                  60   \n",
       "3980                     2                   5                  20   \n",
       "235                      1                   1                  60   \n",
       "5157                     1                   3                  60   \n",
       "\n",
       "      booking_availability_30  booking_availability_60  \\\n",
       "4337                        7                       30   \n",
       "3473                        4                       18   \n",
       "6133                       30                       30   \n",
       "40                         11                       25   \n",
       "3499                       29                       30   \n",
       "...                       ...                      ...   \n",
       "905                        22                       30   \n",
       "5192                        8                       30   \n",
       "3980                        0                        0   \n",
       "235                         0                        0   \n",
       "5157                       23                       30   \n",
       "\n",
       "      booking_availability_90  booking_availability_365  reviews_num  \\\n",
       "4337                       30                         0            1   \n",
       "3473                       30                       275            5   \n",
       "6133                       30                       275            1   \n",
       "40                         22                       272          128   \n",
       "3499                       30                       275            1   \n",
       "...                       ...                       ...          ...   \n",
       "905                        30                       275            1   \n",
       "5192                       30                       234            0   \n",
       "3980                        0                         0            0   \n",
       "235                         0                         0            0   \n",
       "5157                       30                         1            0   \n",
       "\n",
       "      reviews_rating  reviews_acc  reviews_per_month  property_summary_miss  \\\n",
       "4337           100.0         10.0               0.17                      0   \n",
       "3473            90.0          9.0               0.39                      0   \n",
       "6133           100.0         10.0               0.04                      1   \n",
       "40              93.0         10.0               3.35                      0   \n",
       "3499           100.0         10.0               0.16                      0   \n",
       "...              ...          ...                ...                    ...   \n",
       "905             80.0          8.0               1.00                      0   \n",
       "5192           100.0         10.0               1.00                      0   \n",
       "3980           100.0         10.0               1.00                      0   \n",
       "235            100.0         10.0               1.00                      0   \n",
       "5157           100.0         10.0               1.00                      0   \n",
       "\n",
       "      scraped_weekday  property_name_miss  host_since_scraped  \\\n",
       "4337                1                   0                1642   \n",
       "3473                0                   0                 733   \n",
       "6133                1                   0                1428   \n",
       "40                  1                   0                1268   \n",
       "3499                0                   0                 729   \n",
       "...               ...                 ...                 ...   \n",
       "905                 1                   0                   8   \n",
       "5192                1                   0                1544   \n",
       "3980                0                   0                 678   \n",
       "235                 1                   0                1241   \n",
       "5157                0                   0                1546   \n",
       "\n",
       "      property_type_apartment  property_type_bed & breakfast  \\\n",
       "4337                        1                              0   \n",
       "3473                        1                              0   \n",
       "6133                        0                              0   \n",
       "40                          1                              0   \n",
       "3499                        1                              0   \n",
       "...                       ...                            ...   \n",
       "905                         1                              0   \n",
       "5192                        0                              0   \n",
       "3980                        1                              0   \n",
       "235                         1                              0   \n",
       "5157                        1                              0   \n",
       "\n",
       "      property_type_boat  property_type_boutique hotel  property_type_cabin  \\\n",
       "4337                   0                             0                    0   \n",
       "3473                   0                             0                    0   \n",
       "6133                   0                             0                    0   \n",
       "40                     0                             0                    0   \n",
       "3499                   0                             0                    0   \n",
       "...                  ...                           ...                  ...   \n",
       "905                    0                             0                    0   \n",
       "5192                   0                             0                    0   \n",
       "3980                   0                             0                    0   \n",
       "235                    0                             0                    0   \n",
       "5157                   0                             0                    0   \n",
       "\n",
       "      property_type_camper/rv  property_type_castle  property_type_chalet  \\\n",
       "4337                        0                     0                     0   \n",
       "3473                        0                     0                     0   \n",
       "6133                        0                     0                     0   \n",
       "40                          0                     0                     0   \n",
       "3499                        0                     0                     0   \n",
       "...                       ...                   ...                   ...   \n",
       "905                         0                     0                     0   \n",
       "5192                        0                     0                     0   \n",
       "3980                        0                     0                     0   \n",
       "235                         0                     0                     0   \n",
       "5157                        0                     0                     0   \n",
       "\n",
       "      property_type_condominium  property_type_dorm  \\\n",
       "4337                          0                   0   \n",
       "3473                          0                   0   \n",
       "6133                          0                   0   \n",
       "40                            0                   0   \n",
       "3499                          0                   0   \n",
       "...                         ...                 ...   \n",
       "905                           0                   0   \n",
       "5192                          0                   0   \n",
       "3980                          0                   0   \n",
       "235                           0                   0   \n",
       "5157                          0                   0   \n",
       "\n",
       "      property_type_guest suite  property_type_guesthouse  \\\n",
       "4337                          0                         0   \n",
       "3473                          0                         0   \n",
       "6133                          0                         0   \n",
       "40                            0                         0   \n",
       "3499                          0                         0   \n",
       "...                         ...                       ...   \n",
       "905                           0                         0   \n",
       "5192                          0                         0   \n",
       "3980                          0                         0   \n",
       "235                           0                         0   \n",
       "5157                          0                         0   \n",
       "\n",
       "      property_type_hostel  property_type_house  property_type_loft  \\\n",
       "4337                     0                    0                   0   \n",
       "3473                     0                    0                   0   \n",
       "6133                     0                    1                   0   \n",
       "40                       0                    0                   0   \n",
       "3499                     0                    0                   0   \n",
       "...                    ...                  ...                 ...   \n",
       "905                      0                    0                   0   \n",
       "5192                     0                    1                   0   \n",
       "3980                     0                    0                   0   \n",
       "235                      0                    0                   0   \n",
       "5157                     0                    0                   0   \n",
       "\n",
       "      property_type_other  property_type_serviced apartment  \\\n",
       "4337                    0                                 0   \n",
       "3473                    0                                 0   \n",
       "6133                    0                                 0   \n",
       "40                      0                                 0   \n",
       "3499                    0                                 0   \n",
       "...                   ...                               ...   \n",
       "905                     0                                 0   \n",
       "5192                    0                                 0   \n",
       "3980                    0                                 0   \n",
       "235                     0                                 0   \n",
       "5157                    0                                 0   \n",
       "\n",
       "      property_type_townhouse  property_type_villa  property_type_yurt  \\\n",
       "4337                        0                    0                   0   \n",
       "3473                        0                    0                   0   \n",
       "6133                        0                    0                   0   \n",
       "40                          0                    0                   0   \n",
       "3499                        0                    0                   0   \n",
       "...                       ...                  ...                 ...   \n",
       "905                         0                    0                   0   \n",
       "5192                        0                    0                   0   \n",
       "3980                        0                    0                   0   \n",
       "235                         0                    0                   0   \n",
       "5157                        0                    0                   0   \n",
       "\n",
       "      property_room_type_entire home/apt  property_room_type_private room  \\\n",
       "4337                                   0                                1   \n",
       "3473                                   1                                0   \n",
       "6133                                   0                                1   \n",
       "40                                     1                                0   \n",
       "3499                                   1                                0   \n",
       "...                                  ...                              ...   \n",
       "905                                    0                                1   \n",
       "5192                                   1                                0   \n",
       "3980                                   1                                0   \n",
       "235                                    0                                1   \n",
       "5157                                   1                                0   \n",
       "\n",
       "      property_room_type_shared room  property_bed_type_airbed  \\\n",
       "4337                               0                         0   \n",
       "3473                               0                         0   \n",
       "6133                               0                         0   \n",
       "40                                 0                         0   \n",
       "3499                               0                         0   \n",
       "...                              ...                       ...   \n",
       "905                                0                         0   \n",
       "5192                               0                         0   \n",
       "3980                               0                         0   \n",
       "235                                0                         0   \n",
       "5157                               0                         0   \n",
       "\n",
       "      property_bed_type_couch  property_bed_type_futon  \\\n",
       "4337                        0                        0   \n",
       "3473                        0                        0   \n",
       "6133                        0                        0   \n",
       "40                          0                        0   \n",
       "3499                        0                        0   \n",
       "...                       ...                      ...   \n",
       "905                         0                        0   \n",
       "5192                        0                        0   \n",
       "3980                        0                        0   \n",
       "235                         0                        0   \n",
       "5157                        0                        0   \n",
       "\n",
       "      property_bed_type_pull-out sofa  property_bed_type_real bed  \\\n",
       "4337                                0                           1   \n",
       "3473                                0                           1   \n",
       "6133                                0                           1   \n",
       "40                                  0                           1   \n",
       "3499                                0                           1   \n",
       "...                               ...                         ...   \n",
       "905                                 0                           1   \n",
       "5192                                0                           1   \n",
       "3980                                0                           1   \n",
       "235                                 0                           1   \n",
       "5157                                0                           1   \n",
       "\n",
       "      host_response_time_a few days or more  host_response_time_missing  \\\n",
       "4337                                      0                           0   \n",
       "3473                                      0                           0   \n",
       "6133                                      0                           0   \n",
       "40                                        0                           0   \n",
       "3499                                      0                           0   \n",
       "...                                     ...                         ...   \n",
       "905                                       0                           1   \n",
       "5192                                      0                           0   \n",
       "3980                                      0                           1   \n",
       "235                                       0                           1   \n",
       "5157                                      0                           0   \n",
       "\n",
       "      host_response_time_within a day  host_response_time_within a few hours  \\\n",
       "4337                                1                                      0   \n",
       "3473                                1                                      0   \n",
       "6133                                1                                      0   \n",
       "40                                  0                                      0   \n",
       "3499                                0                                      1   \n",
       "...                               ...                                    ...   \n",
       "905                                 0                                      0   \n",
       "5192                                0                                      1   \n",
       "3980                                0                                      0   \n",
       "235                                 0                                      0   \n",
       "5157                                1                                      0   \n",
       "\n",
       "      host_response_time_within an hour  booking_cancel_policy_flexible  \\\n",
       "4337                                  0                               1   \n",
       "3473                                  0                               1   \n",
       "6133                                  0                               1   \n",
       "40                                    1                               0   \n",
       "3499                                  0                               1   \n",
       "...                                 ...                             ...   \n",
       "905                                   0                               0   \n",
       "5192                                  0                               1   \n",
       "3980                                  0                               1   \n",
       "235                                   0                               1   \n",
       "5157                                  0                               0   \n",
       "\n",
       "      booking_cancel_policy_moderate  booking_cancel_policy_strict  \\\n",
       "4337                               0                             0   \n",
       "3473                               0                             0   \n",
       "6133                               0                             0   \n",
       "40                                 1                             0   \n",
       "3499                               0                             0   \n",
       "...                              ...                           ...   \n",
       "905                                1                             0   \n",
       "5192                               0                             0   \n",
       "3980                               0                             0   \n",
       "235                                0                             0   \n",
       "5157                               0                             1   \n",
       "\n",
       "      booking_cancel_policy_super_strict_30  \\\n",
       "4337                                      0   \n",
       "3473                                      0   \n",
       "6133                                      0   \n",
       "40                                        0   \n",
       "3499                                      0   \n",
       "...                                     ...   \n",
       "905                                       0   \n",
       "5192                                      0   \n",
       "3980                                      0   \n",
       "235                                       0   \n",
       "5157                                      0   \n",
       "\n",
       "      property_last_updated_bucket_1 week to 3 months  \\\n",
       "4337                                                1   \n",
       "3473                                                1   \n",
       "6133                                                0   \n",
       "40                                                  1   \n",
       "3499                                                1   \n",
       "...                                               ...   \n",
       "905                                                 0   \n",
       "5192                                                0   \n",
       "3980                                                0   \n",
       "235                                                 0   \n",
       "5157                                                0   \n",
       "\n",
       "      property_last_updated_bucket_3 months or more  \\\n",
       "4337                                              0   \n",
       "3473                                              0   \n",
       "6133                                              1   \n",
       "40                                                0   \n",
       "3499                                              0   \n",
       "...                                             ...   \n",
       "905                                               0   \n",
       "5192                                              0   \n",
       "3980                                              1   \n",
       "235                                               1   \n",
       "5157                                              0   \n",
       "\n",
       "      property_last_updated_bucket_within days  \\\n",
       "4337                                         0   \n",
       "3473                                         0   \n",
       "6133                                         0   \n",
       "40                                           0   \n",
       "3499                                         0   \n",
       "...                                        ...   \n",
       "905                                          1   \n",
       "5192                                         1   \n",
       "3980                                         0   \n",
       "235                                          0   \n",
       "5157                                         1   \n",
       "\n",
       "      host_nr_listings_cat_more than 3  host_nr_listings_cat_one or less  \\\n",
       "4337                                 0                                 1   \n",
       "3473                                 0                                 1   \n",
       "6133                                 0                                 0   \n",
       "40                                   1                                 0   \n",
       "3499                                 0                                 0   \n",
       "...                                ...                               ...   \n",
       "905                                  0                                 1   \n",
       "5192                                 0                                 1   \n",
       "3980                                 0                                 1   \n",
       "235                                  0                                 1   \n",
       "5157                                 1                                 0   \n",
       "\n",
       "      host_nr_listings_cat_two to three  property_bathrooms_cat_More than one  \\\n",
       "4337                                  0                                     1   \n",
       "3473                                  0                                     0   \n",
       "6133                                  1                                     0   \n",
       "40                                    0                                     0   \n",
       "3499                                  1                                     0   \n",
       "...                                 ...                                   ...   \n",
       "905                                   0                                     0   \n",
       "5192                                  0                                     0   \n",
       "3980                                  0                                     0   \n",
       "235                                   0                                     1   \n",
       "5157                                  0                                     0   \n",
       "\n",
       "      property_bathrooms_cat_None  property_bathrooms_cat_One  \\\n",
       "4337                            0                           0   \n",
       "3473                            0                           1   \n",
       "6133                            0                           1   \n",
       "40                              0                           1   \n",
       "3499                            0                           1   \n",
       "...                           ...                         ...   \n",
       "905                             0                           1   \n",
       "5192                            0                           1   \n",
       "3980                            0                           1   \n",
       "235                             0                           0   \n",
       "5157                            0                           1   \n",
       "\n",
       "      propety_beds_cat_0  propety_beds_cat_More than three  \\\n",
       "4337                   0                                 0   \n",
       "3473                   0                                 0   \n",
       "6133                   0                                 0   \n",
       "40                     0                                 0   \n",
       "3499                   0                                 0   \n",
       "...                  ...                               ...   \n",
       "905                    0                                 0   \n",
       "5192                   0                                 0   \n",
       "3980                   0                                 0   \n",
       "235                    0                                 0   \n",
       "5157                   0                                 0   \n",
       "\n",
       "      propety_beds_cat_One  propety_beds_cat_Three  propety_beds_cat_Two  \\\n",
       "4337                     1                       0                     0   \n",
       "3473                     0                       0                     1   \n",
       "6133                     1                       0                     0   \n",
       "40                       1                       0                     0   \n",
       "3499                     1                       0                     0   \n",
       "...                    ...                     ...                   ...   \n",
       "905                      1                       0                     0   \n",
       "5192                     0                       0                     1   \n",
       "3980                     0                       1                     0   \n",
       "235                      1                       0                     0   \n",
       "5157                     1                       0                     0   \n",
       "\n",
       "      property_bedrooms_cat_0  property_bedrooms_cat_More than three  \\\n",
       "4337                        0                                      0   \n",
       "3473                        0                                      0   \n",
       "6133                        0                                      0   \n",
       "40                          0                                      0   \n",
       "3499                        1                                      0   \n",
       "...                       ...                                    ...   \n",
       "905                         0                                      0   \n",
       "5192                        1                                      0   \n",
       "3980                        1                                      0   \n",
       "235                         0                                      0   \n",
       "5157                        0                                      0   \n",
       "\n",
       "      property_bedrooms_cat_One  property_bedrooms_cat_Three  \\\n",
       "4337                          1                            0   \n",
       "3473                          1                            0   \n",
       "6133                          1                            0   \n",
       "40                            1                            0   \n",
       "3499                          0                            0   \n",
       "...                         ...                          ...   \n",
       "905                           1                            0   \n",
       "5192                          0                            0   \n",
       "3980                          0                            0   \n",
       "235                           1                            0   \n",
       "5157                          1                            0   \n",
       "\n",
       "      property_bedrooms_cat_Two  reviews_cleanliness_n_Average  \\\n",
       "4337                          0                              0   \n",
       "3473                          0                              0   \n",
       "6133                          0                              0   \n",
       "40                            0                              0   \n",
       "3499                          0                              1   \n",
       "...                         ...                            ...   \n",
       "905                           0                              0   \n",
       "5192                          0                              1   \n",
       "3980                          0                              1   \n",
       "235                           0                              1   \n",
       "5157                          0                              1   \n",
       "\n",
       "      reviews_cleanliness_n_Bad  reviews_cleanliness_n_Good  \\\n",
       "4337                          0                           1   \n",
       "3473                          0                           1   \n",
       "6133                          0                           1   \n",
       "40                            0                           1   \n",
       "3499                          0                           0   \n",
       "...                         ...                         ...   \n",
       "905                           0                           1   \n",
       "5192                          0                           0   \n",
       "3980                          0                           0   \n",
       "235                           0                           0   \n",
       "5157                          0                           0   \n",
       "\n",
       "      reviews_checkin_n_Average  reviews_checkin_n_Bad  \\\n",
       "4337                          0                      0   \n",
       "3473                          0                      0   \n",
       "6133                          0                      0   \n",
       "40                            0                      0   \n",
       "3499                          1                      0   \n",
       "...                         ...                    ...   \n",
       "905                           0                      0   \n",
       "5192                          1                      0   \n",
       "3980                          1                      0   \n",
       "235                           1                      0   \n",
       "5157                          1                      0   \n",
       "\n",
       "      reviews_checkin_n_Good  reviews_location_n_Average  \\\n",
       "4337                       1                           0   \n",
       "3473                       1                           0   \n",
       "6133                       1                           0   \n",
       "40                         1                           0   \n",
       "3499                       0                           1   \n",
       "...                      ...                         ...   \n",
       "905                        1                           0   \n",
       "5192                       0                           1   \n",
       "3980                       0                           1   \n",
       "235                        0                           1   \n",
       "5157                       0                           1   \n",
       "\n",
       "      reviews_location_n_Bad  reviews_location_n_Good  \\\n",
       "4337                       0                        1   \n",
       "3473                       0                        1   \n",
       "6133                       0                        1   \n",
       "40                         0                        1   \n",
       "3499                       0                        0   \n",
       "...                      ...                      ...   \n",
       "905                        0                        1   \n",
       "5192                       0                        0   \n",
       "3980                       0                        0   \n",
       "235                        0                        0   \n",
       "5157                       0                        0   \n",
       "\n",
       "      reviews_communication_n_Average  reviews_communication_n_Bad  \\\n",
       "4337                                0                            0   \n",
       "3473                                0                            0   \n",
       "6133                                0                            0   \n",
       "40                                  0                            0   \n",
       "3499                                1                            0   \n",
       "...                               ...                          ...   \n",
       "905                                 0                            0   \n",
       "5192                                1                            0   \n",
       "3980                                1                            0   \n",
       "235                                 1                            0   \n",
       "5157                                1                            0   \n",
       "\n",
       "      reviews_communication_n_Good  reviews_value_n_Average  \\\n",
       "4337                             1                        0   \n",
       "3473                             1                        0   \n",
       "6133                             1                        0   \n",
       "40                               1                        0   \n",
       "3499                             0                        1   \n",
       "...                            ...                      ...   \n",
       "905                              1                        0   \n",
       "5192                             0                        1   \n",
       "3980                             0                        1   \n",
       "235                              0                        1   \n",
       "5157                             0                        1   \n",
       "\n",
       "      reviews_value_n_Bad  reviews_value_n_Good  1000  1050  1060  2000  1030  \\\n",
       "4337                    0                     1     0     0     0     0     0   \n",
       "3473                    0                     1     0     1     0     0     0   \n",
       "6133                    0                     1     0     0     1     0     0   \n",
       "40                      0                     1     0     0     0     0     0   \n",
       "3499                    0                     0     1     0     0     0     0   \n",
       "...                   ...                   ...   ...   ...   ...   ...   ...   \n",
       "905                     0                     1     0     0     0     0     0   \n",
       "5192                    0                     0     1     0     0     0     0   \n",
       "3980                    0                     0     0     1     0     0     0   \n",
       "235                     0                     0     0     0     0     0     0   \n",
       "5157                    0                     0     0     0     1     0     0   \n",
       "\n",
       "      1040  1190  2018  1180  1070  \n",
       "4337     0     0     0     0     0  \n",
       "3473     0     0     0     0     0  \n",
       "6133     0     0     0     0     0  \n",
       "40       0     0     0     0     0  \n",
       "3499     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...  \n",
       "905      1     0     0     0     0  \n",
       "5192     0     0     0     0     0  \n",
       "3980     0     0     0     0     0  \n",
       "235      0     0     0     0     0  \n",
       "5157     0     0     0     0     0  \n",
       "\n",
       "[4808 rows x 104 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(\n",
    "     steps=[\n",
    "        ('columnDropper', FunctionTransformer(columnDropperTransformer, kw_args={'cols':['property_id','property_space','property_desc','property_neighborhood','property_notes','property_access',\n",
    "                                     \"property_interaction\",\"property_rules\",\"host_location\",\"host_about\",\"host_id\", 'property_transit', 'property_lon', \n",
    "                                     'property_lat', 'property_sqfeet',\"host_nr_listings_total\",\"extra\"]})),\n",
    "        # Drops min nights outliers\n",
    "        (\"min_nights_transform\",FunctionTransformer(min_nights_transform,kw_args={'col':'booking_min_nights'})),\n",
    "    \n",
    "        (\"change_datetime_format\", FunctionTransformer(change_datetime_format,kw_args={'cols':['property_scraped_at','host_since','reviews_first','reviews_last']})),\n",
    "        (\"summaryMissing\", FunctionTransformer(SummaryMissing, kw_args={'col':'property_summary','new_col':'property_summary_miss'})),\n",
    "        (\"missing_cat\",FunctionTransformer(missing_cat,kw_args={'col':'host_response_time'})),\n",
    "        (\"missing_to_100\",FunctionTransformer(missing_to_100,kw_args={'col':'host_response_rate'})),\n",
    "        (\"booking_availability_transform\", FunctionTransformer(booking_availability_transform,kw_args={'col':'booking_availability_365'})),\n",
    "        \n",
    "        (\"add_scrapped_weekday\",FunctionTransformer(add_scrapped_weekday,kw_args={'cols':'property_scraped_at','new_cols':'scraped_weekday'})),\n",
    "        (\"last_updated_wrap\",FunctionTransformer(last_updated_wrap,kw_args={'col':'property_last_updated','new_col':'property_last_updated_bucket'})),\n",
    "        (\"listing_number_transform\", FunctionTransformer(listing_number_transform,kw_args={'col':'host_nr_listings','new_col':'host_nr_listings_cat'})),\n",
    "        ('splitOnComma', FunctionTransformer(splitOnComma, kw_args={'col':'property_amenities'})),\n",
    "        # # replacing missing with mode\n",
    "        (\"replaceWithMode\", FunctionTransformer(replaceWithMode, kw_args={'cols': ['property_zipcode', 'property_bathrooms', 'reviews_per_month',\n",
    "                                                                                   'host_since','reviews_first','reviews_last','reviews_rating','reviews_acc']})),\n",
    "        ('removeSpaces', FunctionTransformer(removeSpaces, kw_args={'cols': ['property_zipcode']}))  ,                                                                         \n",
    "        (\"max_nights_transform\", FunctionTransformer(max_nights_transform,kw_args={'col':'booking_max_nights'})),\n",
    "        # # replacing missing with zero\n",
    "        ('replaceWithZero', FunctionTransformer(replacewithZero, kw_args ={'cols':['property_beds', 'property_bedrooms','property_amenities']})),\n",
    "        (\"miss\",FunctionTransformer(isMissing, kw_args = {'col' :['property_name'],'new_col':['property_name_miss']})),\n",
    "        (\"lowercase\", toLowerCase()),\n",
    "        ('splitCount', FunctionTransformer(splitCountWords,kw_args={'cols':['property_name', 'property_summary','host_verified']})),\n",
    "        ('propertyRegrouping', FunctionTransformer(featureGrouping, kw_args = {'col':'property_type'})),\n",
    "        ('BathroomsCount',FunctionTransformer(BathroomsCount, kw_args ={'col':'property_bathrooms', 'new_col':'property_bathrooms_cat'})),\n",
    "        # ('powerTransform', col_trans), #TODO: fix the bug \n",
    "        # Only run after scrapped_date functions\n",
    "        ('host_since_transform',FunctionTransformer(host_since_transform,kw_args={'col':'host_since'})),\n",
    "        # ('reviews_date_transform',FunctionTransformer(reviews_date_transform,kw_args={'cols':['reviews_first','reviews_last'],'new_cols':['reviews_first_since_scraped',\n",
    "        #                                                                                                                                   'reviews_last_since_scraped']})),\n",
    "        ('numToCategory', FunctionTransformer(NumToCategory, kw_args={'cols':['property_beds','property_bedrooms'], 'new_cols':['propety_beds_cat', 'property_bedrooms_cat']})),\n",
    "        ('reviewRecoding', FunctionTransformer(reviewRecoding, kw_args={'cols':['reviews_cleanliness','reviews_checkin','reviews_location','reviews_communication','reviews_value'], 'new_cols':[\n",
    "    'reviews_cleanliness_n','reviews_checkin_n','reviews_location_n','reviews_communication_n','reviews_value_n']\n",
    "        })),\n",
    "        ('SecondcolumnDropper', FunctionTransformer(columnDropperTransformer, kw_args={'cols':[\"col\",\"property_scraped_at\"]})),\n",
    "        ('One_Hot', FunctionTransformer(one_hot_func, kw_args={'col':non_numeric_cols})),\n",
    "        ('Zip_code_func', FunctionTransformer(zip_func, kw_args={'col':'property_zipcode'}))\n",
    "    ]\n",
    ")\n",
    "df= pipe.fit_transform(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: bool)\n"
     ]
    }
   ],
   "source": [
    "nans = df.isna().any()\n",
    "print(nans.loc[nans==True])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X4o4-JLV1csx",
    "tags": []
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "O3dwKNe-xvhM",
    "outputId": "8c3b58a7-c652-4f7d-f831-69905b4b7c28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping this would be the same as the word doc table\n",
    "feature_train = feature_train.drop(['property_id','property_space','property_desc','property_neighborhood','property_notes','property_access',\n",
    "                                    \"property_interaction\",\"property_rules\",\"host_location\",\"host_about\",\"host_id\",\"property_sqfeet\"], axis = 1)\n",
    "feature_train = feature_train.drop([\"property_transit\"],axis=1)\n",
    "transformed_train = pd.DataFrame()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gDYy-zH8C_wT",
    "outputId": "fedf0313-e092-429c-80a1-a98907acbc6f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_name</th>\n",
       "      <th>property_summary</th>\n",
       "      <th>property_zipcode</th>\n",
       "      <th>property_lat</th>\n",
       "      <th>property_lon</th>\n",
       "      <th>property_type</th>\n",
       "      <th>property_room_type</th>\n",
       "      <th>property_max_guests</th>\n",
       "      <th>property_bathrooms</th>\n",
       "      <th>property_bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews_last</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>reviews_acc</th>\n",
       "      <th>reviews_cleanliness</th>\n",
       "      <th>reviews_checkin</th>\n",
       "      <th>reviews_communication</th>\n",
       "      <th>reviews_location</th>\n",
       "      <th>reviews_value</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>quiet and cosy space in the heart of the city.</td>\n",
       "      <td>our second bedroom is an ideal base to explore...</td>\n",
       "      <td>1080</td>\n",
       "      <td>50.857650</td>\n",
       "      <td>4.345135</td>\n",
       "      <td>apartment</td>\n",
       "      <td>private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>host has profile pic, host identity verified, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>charming duplex</td>\n",
       "      <td>charming duplex in one of the liveliest areas ...</td>\n",
       "      <td>1050</td>\n",
       "      <td>50.837916</td>\n",
       "      <td>4.365566</td>\n",
       "      <td>apartment</td>\n",
       "      <td>entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>host has profile pic, host identity verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>lovely room in saint gilles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060</td>\n",
       "      <td>50.824260</td>\n",
       "      <td>4.351169</td>\n",
       "      <td>house</td>\n",
       "      <td>private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-06-21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>host has profile pic, host identity verified, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>furnished loft in brussels city</td>\n",
       "      <td>lovely furnished loft under the roof of an aut...</td>\n",
       "      <td>1210</td>\n",
       "      <td>50.849647</td>\n",
       "      <td>4.372477</td>\n",
       "      <td>apartment</td>\n",
       "      <td>entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>host has profile pic, host identity verified, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>nice bright studio apartment</td>\n",
       "      <td>you’ll love my place because of the light and ...</td>\n",
       "      <td>1000</td>\n",
       "      <td>50.821778</td>\n",
       "      <td>4.366841</td>\n",
       "      <td>apartment</td>\n",
       "      <td>entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>host has profile pic, is location exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>belle chambre à etterbeek proche quartier euro...</td>\n",
       "      <td>au 2ème étage sans ascenseur, bel appartement ...</td>\n",
       "      <td>1040</td>\n",
       "      <td>50.826435</td>\n",
       "      <td>4.387064</td>\n",
       "      <td>apartment</td>\n",
       "      <td>private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>host has profile pic, is location exact, insta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>studio duplex in historical center</td>\n",
       "      <td>arty and cosy.  light flat on 3rd floor (no li...</td>\n",
       "      <td>1000</td>\n",
       "      <td>50.845946</td>\n",
       "      <td>4.345088</td>\n",
       "      <td>house</td>\n",
       "      <td>entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>host has profile pic, host identity verified, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>quiet cocoon  in ixelles!</td>\n",
       "      <td>bright and quiet flat close to avenue louise, ...</td>\n",
       "      <td>1050</td>\n",
       "      <td>50.831855</td>\n",
       "      <td>4.364576</td>\n",
       "      <td>apartment</td>\n",
       "      <td>entire home/apt</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>host has profile pic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>petine chambre sur le jardin</td>\n",
       "      <td>chambre petite mais confortable avec un accès ...</td>\n",
       "      <td>1210</td>\n",
       "      <td>50.851290</td>\n",
       "      <td>4.375520</td>\n",
       "      <td>apartment</td>\n",
       "      <td>private room</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>host has profile pic, is location exact, insta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>cosy 1bedroom+balcony ixelles 2425</td>\n",
       "      <td>spacious and cosy one bedroom apartment for va...</td>\n",
       "      <td>1060</td>\n",
       "      <td>50.833083</td>\n",
       "      <td>4.352898</td>\n",
       "      <td>apartment</td>\n",
       "      <td>entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>host has profile pic, host identity verified, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4871 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          property_name  \\\n",
       "4337     quiet and cosy space in the heart of the city.   \n",
       "3473                                    charming duplex   \n",
       "6133                        lovely room in saint gilles   \n",
       "40                      furnished loft in brussels city   \n",
       "3499                       nice bright studio apartment   \n",
       "...                                                 ...   \n",
       "905   belle chambre à etterbeek proche quartier euro...   \n",
       "5192                 studio duplex in historical center   \n",
       "3980                          quiet cocoon  in ixelles!   \n",
       "235                        petine chambre sur le jardin   \n",
       "5157                 cosy 1bedroom+balcony ixelles 2425   \n",
       "\n",
       "                                       property_summary property_zipcode  \\\n",
       "4337  our second bedroom is an ideal base to explore...             1080   \n",
       "3473  charming duplex in one of the liveliest areas ...             1050   \n",
       "6133                                                NaN             1060   \n",
       "40    lovely furnished loft under the roof of an aut...             1210   \n",
       "3499  you’ll love my place because of the light and ...             1000   \n",
       "...                                                 ...              ...   \n",
       "905   au 2ème étage sans ascenseur, bel appartement ...             1040   \n",
       "5192  arty and cosy.  light flat on 3rd floor (no li...             1000   \n",
       "3980  bright and quiet flat close to avenue louise, ...             1050   \n",
       "235   chambre petite mais confortable avec un accès ...             1210   \n",
       "5157  spacious and cosy one bedroom apartment for va...             1060   \n",
       "\n",
       "      property_lat  property_lon property_type property_room_type  \\\n",
       "4337     50.857650      4.345135     apartment       private room   \n",
       "3473     50.837916      4.365566     apartment    entire home/apt   \n",
       "6133     50.824260      4.351169         house       private room   \n",
       "40       50.849647      4.372477     apartment    entire home/apt   \n",
       "3499     50.821778      4.366841     apartment    entire home/apt   \n",
       "...            ...           ...           ...                ...   \n",
       "905      50.826435      4.387064     apartment       private room   \n",
       "5192     50.845946      4.345088         house    entire home/apt   \n",
       "3980     50.831855      4.364576     apartment    entire home/apt   \n",
       "235      50.851290      4.375520     apartment       private room   \n",
       "5157     50.833083      4.352898     apartment    entire home/apt   \n",
       "\n",
       "      property_max_guests  property_bathrooms  property_bedrooms  ...  \\\n",
       "4337                    2                 1.5                1.0  ...   \n",
       "3473                    2                 1.0                1.0  ...   \n",
       "6133                    2                 1.0                1.0  ...   \n",
       "40                      2                 1.0                1.0  ...   \n",
       "3499                    2                 1.0                0.0  ...   \n",
       "...                   ...                 ...                ...  ...   \n",
       "905                     2                 1.0                1.0  ...   \n",
       "5192                    2                 1.0                0.0  ...   \n",
       "3980                    5                 1.0                0.0  ...   \n",
       "235                     1                 4.0                1.0  ...   \n",
       "5157                    3                 1.0                1.0  ...   \n",
       "\n",
       "      reviews_last reviews_rating reviews_acc reviews_cleanliness  \\\n",
       "4337    2016-11-11          100.0        10.0                10.0   \n",
       "3473    2017-04-17           90.0         9.0                 9.0   \n",
       "6133    2015-06-21          100.0        10.0                10.0   \n",
       "40      2017-04-17           93.0        10.0                 9.0   \n",
       "3499    2016-11-08            NaN         NaN                 NaN   \n",
       "...            ...            ...         ...                 ...   \n",
       "905     2017-05-06           80.0         8.0                10.0   \n",
       "5192           NaN            NaN         NaN                 NaN   \n",
       "3980           NaN            NaN         NaN                 NaN   \n",
       "235            NaN            NaN         NaN                 NaN   \n",
       "5157           NaN            NaN         NaN                 NaN   \n",
       "\n",
       "     reviews_checkin reviews_communication reviews_location  reviews_value  \\\n",
       "4337            10.0                  10.0             10.0           10.0   \n",
       "3473            10.0                  10.0              8.0            9.0   \n",
       "6133            10.0                  10.0             10.0           10.0   \n",
       "40              10.0                  10.0              9.0            9.0   \n",
       "3499             NaN                   NaN              NaN            NaN   \n",
       "...              ...                   ...              ...            ...   \n",
       "905             10.0                  10.0             10.0           10.0   \n",
       "5192             NaN                   NaN              NaN            NaN   \n",
       "3980             NaN                   NaN              NaN            NaN   \n",
       "235              NaN                   NaN              NaN            NaN   \n",
       "5157             NaN                   NaN              NaN            NaN   \n",
       "\n",
       "      reviews_per_month                                              extra  \n",
       "4337               0.17  host has profile pic, host identity verified, ...  \n",
       "3473               0.39       host has profile pic, host identity verified  \n",
       "6133               0.04  host has profile pic, host identity verified, ...  \n",
       "40                 3.35  host has profile pic, host identity verified, ...  \n",
       "3499               0.16            host has profile pic, is location exact  \n",
       "...                 ...                                                ...  \n",
       "905                1.00  host has profile pic, is location exact, insta...  \n",
       "5192                NaN  host has profile pic, host identity verified, ...  \n",
       "3980                NaN                               host has profile pic  \n",
       "235                 NaN  host has profile pic, is location exact, insta...  \n",
       "5157                NaN  host has profile pic, host identity verified, ...  \n",
       "\n",
       "[4871 rows x 41 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All df to lower case -works\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def toLower(df):\n",
    "    df = df.apply(lambda x: x.str.lower() if x.dtype=='object' else x)\n",
    "    return df\n",
    "\n",
    "toLower = FunctionTransformer(toLower)\n",
    "toLower.fit_transform(feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "r-lgZs-gGd9S",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Property name: replaced by the word count & new column:missing? - works\n",
    "\n",
    "feature_train['property_name_miss'] = np.where(feature_train['property_name'].isna(), 1, 0)\n",
    "# Should refactor this because if run twice it throws an error\n",
    "feature_train.property_name = feature_train['property_name'].str.split().str.len()\n",
    "feature_train.property_name = feature_train.property_name.fillna(0)\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train.property_name],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,feature_train.property_name_miss],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "6pCUDZaQJWXz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Property summary: new columns - summary_missing & property_summary_count\n",
    "## Missing = 'nan' or one word in summary\n",
    "str_df  = pd.DataFrame()\n",
    "str_df['condition'] = feature_train['property_summary'].str.match(r'\\A[\\w-]+\\Z')\n",
    "\n",
    "feature_train = pd.merge(str_df, feature_train, left_index=True, right_index=True)\n",
    "feature_train['property_summary_miss'] = np.where(feature_train['condition'].isna(), 1, 0)\n",
    "feature_train = feature_train.drop(['condition'], axis = 1)\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train.property_summary_miss],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZT08_2_KH3S",
    "outputId": "078d7937-3eb1-444a-f3c0-7c41ca498cab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svnel\\AppData\\Local\\Temp\\ipykernel_15072\\3509982662.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  feature_train['property_summary'] = feature_train['property_summary'].str.replace('\\d+', '')\n",
      "C:\\Users\\svnel\\AppData\\Local\\Temp\\ipykernel_15072\\3509982662.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  feature_train['property_summary'] = feature_train['property_summary'].str.replace('[^\\w\\s]',' ')\n"
     ]
    }
   ],
   "source": [
    "## Property_summary_count: remove numbers, punctuation \n",
    "feature_train['property_summary'] = feature_train['property_summary'].str.replace('\\d+', '')\n",
    "feature_train['property_summary'] = feature_train['property_summary'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "feature_train['property_summary_count'] = feature_train['property_summary'].str.split().str.len()\n",
    "feature_train = feature_train.drop(['property_summary'], axis = 1)\n",
    "feature_train.property_summary_count = feature_train.property_summary_count.fillna(0)\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train.property_summary_count],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "9olRvfdScwOv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_zipcode: replaced with mode\n",
    "zipcode_mode=feature_train['property_zipcode'].mode()[0]\n",
    "feature_train['property_zipcode'] = feature_train['property_zipcode'] .fillna(feature_train['property_zipcode'].mode()[0])\n",
    "\n",
    "feature_train.loc[feature_train['property_zipcode']=='11 20','property_zipcode']=1120\n",
    "\n",
    "freq_table=feature_train['property_zipcode'].value_counts()\n",
    "\n",
    "#encoding: preserve 11 most frequent categories\n",
    "feature_train.property_zipcode=feature_train.property_zipcode.astype(int)\n",
    "zipcode_cats = pd.get_dummies(feature_train.property_zipcode)\n",
    "sorted_zipcode_cats = zipcode_cats[zipcode_cats.sum().sort_values(ascending=False).index]\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,sorted_zipcode_cats.iloc[:,:10]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "XM3EHxBjFBbw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_type: regrouped into - apartment, house, other\n",
    "threshold_percent = 3\n",
    "\n",
    "series = pd.value_counts(feature_train['property_type'])\n",
    "mask = (series / series.sum() * 100).lt(threshold_percent)\n",
    "\n",
    "feature_train = feature_train.assign(property_type = np.where(feature_train['property_type'].isin(series[mask].index),'Other', feature_train['property_type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encode property_type\n",
    "type_cats = pd.get_dummies(feature_train['property_type'])\n",
    "transformed_train = pd.concat([transformed_train,type_cats],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVVdqqzHIoib",
    "outputId": "e890de89-01a6-4120-856d-d8c349b4b5b4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_bathrooms: regroup into 1. None 2. One 3. More than one\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bathrooms_mode = feature_train['property_bathrooms'].mode()\n",
    "feature_train['property_bathrooms'] =feature_train['property_bathrooms'].fillna(feature_train['property_bathrooms'].mode())\n",
    "\n",
    "np.unique(feature_train['property_bathrooms'],return_counts=True)\n",
    "\n",
    "feature_train['property_bathrooms_cat']= 'One'\n",
    "feature_train.loc[(feature_train['property_bathrooms'] < 1) , 'property_bathrooms_cat'] = 'None'\n",
    "feature_train.loc[(feature_train['property_bathrooms'] > 1), 'property_bathrooms_cat'] = 'More than one'\n",
    "\n",
    "feature_train = feature_train.drop(['property_bathrooms'], axis = 1)\n",
    "feature_train['property_bathrooms_cat']\n",
    "\n",
    "bathroom_cats = pd.get_dummies(feature_train['property_bathrooms_cat'])\n",
    "transformed_train = pd.concat([transformed_train,bathroom_cats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-LkSfEi8RLhs",
    "outputId": "ee353fab-82bb-4b48-e1c0-33a1fd8233cd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_bedrooms\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "def NumToCategory(df, column,new_column, missing_value = 0):\n",
    "  df[column] =df[column].fillna(missing_value)\n",
    "\n",
    "  df.loc[(df[column] == 1), new_column] = 'One'\n",
    "  df.loc[(df[column] == 2), new_column] = 'Two'\n",
    "  df.loc[(df[column] == 3), new_column] = 'Three'\n",
    "  df.loc[(df[column] > 3), new_column] = 'More than three'\n",
    "\n",
    "  df = df.drop([column], axis = 1)\n",
    "  return df\n",
    "\n",
    "feature_train = NumToCategory(feature_train, 'property_beds', 'property_beds_cat')\n",
    "feature_train = NumToCategory(feature_train, 'property_bedrooms', 'property_bedrooms_cat')\n",
    "\n",
    "beds_dummies = pd.get_dummies(feature_train['property_beds_cat'])\n",
    "bedrooms_dummies = pd.get_dummies(feature_train['property_bedrooms_cat'])\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,beds_dummies,bedrooms_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHnFSmNChhgP",
    "outputId": "3761aa15-12f9-4840-afc0-fd2b03fa4fa4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_bed_type: ok\n",
    "feature_train['property_bed_type'].unique()\n",
    "# room type: ok\n",
    "pd.value_counts(feature_train['property_room_type'])\n",
    "\n",
    "\n",
    "roomtype_cat = pd.get_dummies(feature_train['property_room_type'])\n",
    "transformed_train = pd.concat([transformed_train,roomtype_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Oj8BhSP9iGHW",
    "outputId": "223a8e76-dd8b-4fb8-bec5-188f5ea20ddc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_amenities: count the number of amenities provided\n",
    "# remove nans by the mode \n",
    "\n",
    "# reviews_num: Power transform for skeweness \n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import skewtest\n",
    "\n",
    "\n",
    "feature_train['property_amenities'] =  feature_train['property_amenities'].str.split(', ').str.len()\n",
    "amenities_mode = feature_train['property_amenities'].mode()[0]\n",
    "feature_train['property_amenities'] = feature_train['property_amenities'].fillna(feature_train['property_amenities'].mode()[0])\n",
    "\n",
    "def powerTransform(df, column):\n",
    "  col  = np.array( df[column]).reshape(-1, 1)\n",
    "  pt = PowerTransformer(method='yeo-johnson', standardize=True,) \n",
    "  fit = pt.fit(col)\n",
    "  fit = pt.transform(col)\n",
    "  df[column] = fit\n",
    "  return df\n",
    "\n",
    "feature_train = powerTransform(feature_train,'property_amenities')\n",
    "feature_train = powerTransform(feature_train,'reviews_num')\n",
    "\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train.property_amenities],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,feature_train.reviews_num],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "-vxpyxsoS7aH",
    "outputId": "197f13ad-d9ba-4c70-e0ce-99e5ae6691e3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_cleanliness\n",
    "# Good: above 5, Bad: below 5, None: average (could be set to \"Missing\", but people who find a property okay usually dont leave reviews, hence, average. Missing might be misleading)\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def reviewRecoding(df, column, new_column):\n",
    "  df[new_column] = df[column].fillna('Average')\n",
    "  df.loc[(df[column] <= 5) , new_column] = 'Bad'\n",
    "  df.loc[(df[column] > 5), new_column] = 'Good'\n",
    "  df = df.drop([column], axis = 1)\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_train = reviewRecoding(feature_train, 'reviews_cleanliness', 'reviews_cleanliness_n')\n",
    "feature_train = reviewRecoding(feature_train, 'reviews_checkin', 'reviews_checkin_n')\n",
    "feature_train = reviewRecoding(feature_train, 'reviews_location', 'reviews_communication_n')\n",
    "feature_train = reviewRecoding(feature_train, 'reviews_communication', 'reviews_communication_n')\n",
    "feature_train = reviewRecoding(feature_train, 'reviews_value', 'reviews_value_n')\n",
    "\n",
    "cleanliness_cat = pd.get_dummies(feature_train['reviews_cleanliness_n'])\n",
    "checkin_cat = pd.get_dummies(feature_train['reviews_checkin_n'])\n",
    "location_cat = pd.get_dummies(feature_train['reviews_communication_n'])\n",
    "communication_cat = pd.get_dummies(feature_train['reviews_communication_n'])\n",
    "value_cat = pd.get_dummies(feature_train['reviews_value_n'])\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,cleanliness_cat],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,checkin_cat],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,location_cat],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,communication_cat],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,value_cat],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "h44e1pGphnU-",
    "outputId": "c213aa80-c242-4cca-9bc6-6478fbcb577d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_per_month (avg): right skewed - log transform\n",
    "#add 1 to all to avoid log problems\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "reviews_per_month_mode = feature_train['reviews_per_month'].mode()\n",
    "\n",
    "feature_train['reviews_per_month'] =feature_train['reviews_per_month'].fillna(feature_train['reviews_per_month'].mode())\n",
    "feature_train['reviews_per_month'] =feature_train['reviews_per_month']+1\n",
    "def reviewsLog(df, feature):\n",
    "  logTr = ColumnTransformer(transformers=[('lg', FunctionTransformer(np.log),[feature])])\n",
    "  log = logTr.fit_transform(df)\n",
    "  df[feature] = log\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_train = reviewsLog(feature_train, 'reviews_per_month')\n",
    "feature_train.reviews_per_month = feature_train.reviews_per_month.fillna(0)\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train.reviews_per_month],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "uB-NrJX7CFtB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_scraped_at\n",
    "feature_train['property_scraped_at']= pd.to_datetime(feature_train['property_scraped_at'])\n",
    "feature_train['scraped_weekday']=feature_train['property_scraped_at'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encode property_scraped_at\n",
    "start_year = 2017\n",
    "days_since_2017 = (feature_train['property_scraped_at'] - pd.Timestamp(str(start_year))).dt.days\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,days_since_2017],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "5PTDekClz4lj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# property_last_updated\n",
    "# Naturally last_updated is a string :))))))\n",
    "\n",
    "def last_updated_conversion(update_var:str):\n",
    "  # 3 Buckets evenly distributed based on train, 2 for > 3 months, 0 for updated yesterday/today\n",
    "  if \"never\" in update_var:\n",
    "    return \"3 months or more\"\n",
    "  elif \"month\" in update_var:\n",
    "    if int(update_var.split(\" \")[0])>=3:\n",
    "      return \"3 months or more\"\n",
    "    else:\n",
    "      return \"1 week to 3 months\"\n",
    "  elif \"week\" in update_var:\n",
    "    return \"1 week to 3 months\"\n",
    "  else: # This catches yesterday etc. is actually equivalent to \"day\" in update_var\n",
    "    return \"Within days\"\n",
    "\n",
    "feature_train[\"property_last_updated_bucket\"] = [last_updated_conversion(x) for x in feature_train[\"property_last_updated\"]] \n",
    "feature_train = feature_train.drop([\"property_last_updated\"], axis = 1) # Dropping old columns\n",
    "\n",
    "last_updated_cat = pd.get_dummies(feature_train['property_last_updated_bucket'])\n",
    "transformed_train = pd.concat([transformed_train,last_updated_cat],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SrrKDu1tEfGr"
   },
   "source": [
    "Decided to drop host_id because the main information we expected from this is contained in host_nr_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "S1nEcZj-z_5n",
    "outputId": "63d2d54e-e392-4676-b451-b0068271b546",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# host_since\n",
    "\n",
    "\n",
    "feature_train['host_since']=pd.to_datetime(feature_train['host_since'])\n",
    "host_since_mean = feature_train['host_since'].mean()\n",
    "feature_train['host_since'] = feature_train['host_since'].fillna(host_since_mean) # Simply imputing with mean, only had 1 NA anyways\n",
    "feature_train['host_since_scraped'] = feature_train['property_scraped_at']-feature_train['host_since']\n",
    "feature_train['host_since_scraped'] = feature_train['host_since_scraped'].dt.days.astype('int16')\n",
    "#feature_train['host_since_scraped'].hist()\n",
    "feature_train = feature_train.drop(['host_since'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['host_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "MiMepGGd0DS2",
    "outputId": "f2e4488c-ceec-490a-cff4-c6bbf437f35d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# host_response_time\n",
    "# Given 1k NAN decided to add extra missing category as never having received messages might be a signal, otherwise seems fine\n",
    "feature_train['host_response_time']=feature_train['host_response_time'].fillna(value=\"Missing\",inplace=True)\n",
    "#feature_train['host_response_time'].hist()\n",
    "\n",
    "host_response_cat = pd.get_dummies(feature_train['host_response_time'])\n",
    "transformed_train = pd.concat([transformed_train,host_response_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "IH9tg3AY0vxy",
    "outputId": "8b73cd29-2fc8-49eb-c684-90846b3ba60f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# host_response_rate\n",
    "# Impute 100% response rate for never having received a request which is \"fair\"\n",
    "feature_train['host_response_rate']=feature_train['host_response_rate'].fillna(value=100)\n",
    "# Similar to Rating skewness\n",
    "#feature_train['host_response_rate'].hist()\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['host_response_rate']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "Xb0bIBdE0z3H",
    "outputId": "cb03eb02-cf11-4d95-d3de-24760bb533bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# host_nr_listings, host_nr_listings_total\n",
    "# Decided to drop host_nr_listings_total for now as it is basically the same information as host_nr_listings in the training set,\n",
    "# if one wants to squeeze more information out one could take the difference between the two as an extra feature\n",
    "# Basically everyone only has 1 property\n",
    "if \"host_nr_listings_total\" in feature_train.columns:\n",
    "  feature_train = feature_train.drop(['host_nr_listings_total'], axis = 1)\n",
    "\n",
    "feature_train.loc[(feature_train['host_nr_listings'] <= 1) , 'host_nr_listings_cat'] = 'One or less'\n",
    "feature_train.loc[(feature_train['host_nr_listings'] > 1) & (feature_train['host_nr_listings'] <=3), 'host_nr_listings_cat'] = 'Two to Three'\n",
    "feature_train.loc[(feature_train['host_nr_listings'] > 3), 'host_nr_listings_cat'] = 'More than 3'\n",
    "\n",
    "#feature_train['host_nr_listings_cat'].hist()\n",
    "feature_train = feature_train.drop(['host_nr_listings'], axis = 1) # Dropping old columns\n",
    "\n",
    "nr_listings_cat = pd.get_dummies(feature_train['host_nr_listings_cat'])\n",
    "transformed_train = pd.concat([transformed_train,nr_listings_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "88SZmOmK1Or6",
    "outputId": "ea70a231-ace0-418a-8f7a-1995b04de979",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# host_verified\n",
    "# csv sheet including everything that is \"verified\" e.g. email,phone reviews etc.\n",
    "# Same procedure as with property_summary\n",
    "feature_train['host_verified_count'] = feature_train['host_verified'].str.split(\",\").str.len()\n",
    "#feature_train['host_verified_count'].hist()\n",
    "feature_train = feature_train.drop(['host_verified'], axis = 1) # Dropping old columns\n",
    "\n",
    "feature_train['host_verified_count'] = feature_train['host_verified_count'].fillna(0)\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['host_verified_count']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "6qCdClt51SQC",
    "outputId": "2078a091-44d8-46a9-fcdf-11fb51d56937",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# booking_price_covers \n",
    "# Number of people that can live in the property for the price\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#feature_train['booking_price_covers'].hist()\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['booking_price_covers']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "_KRWkVxz1V7x",
    "outputId": "8c1e2a37-bf92-49c3-b424-49e799fa5bbe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# booking_min_nights\n",
    "# No NAs\n",
    "# Choosing to drop anything that requires booking more than 1 month which is only 37 observations. It should be noted that this will lead to us losing\n",
    "# some information on longterm rentals but I think this is preferable, in particular as these might be faulty observations anyways\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#for now: cap at 31\n",
    "feature_train.loc[feature_train[\"booking_max_nights\"] >31, \"booking_max_nights\"] = 31\n",
    "feature_train['booking_min_nights'].hist()\n",
    "transformed_train = pd.concat([transformed_train,feature_train['booking_min_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "f1iOG8mO1X0p",
    "outputId": "380059d1-e31b-4a52-e1ad-2967fea8bb89",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# booking_max_nights\n",
    "# no NAs\n",
    "# Capped everything above 2 months \n",
    "feature_train.loc[feature_train[\"booking_max_nights\"] >60, \"booking_max_nights\"] = 60\n",
    "#feature_train['booking_max_nights'].hist()\n",
    "transformed_train = pd.concat([transformed_train,feature_train['booking_max_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "xQgRX43N3T21",
    "outputId": "980688a0-c123-48b8-c3f5-a899e2e62b65",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# booking_cancel_policy\n",
    "# Seems fine\n",
    "#feature_train['booking_cancel_policy'].hist()\n",
    "\n",
    "cancel_cat = pd.get_dummies(feature_train['booking_cancel_policy'])\n",
    "transformed_train = pd.concat([transformed_train,cancel_cat],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "ALEFF731OV6K",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# booking_availability_30/60/90/365\n",
    "# No NAs in any of them\n",
    "# Transform availabilities into representing the availability of respective time periods (e.g. 365-90 day availability = availability for last 9 months)\n",
    "# Only execute once\n",
    "\n",
    "feature_train['booking_availability_365'] = feature_train['booking_availability_365']-feature_train['booking_availability_90']\n",
    "feature_train['booking_availability_90'] = feature_train['booking_availability_90'] - feature_train['booking_availability_60']\n",
    "feature_train['booking_availability_60'] = feature_train['booking_availability_60']- feature_train['booking_availability_30']\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['booking_availability_30']],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,feature_train['booking_availability_60']],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,feature_train['booking_availability_90']],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,feature_train['booking_availability_365']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "E9Ih87cciK8k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# review_first, review_last\n",
    "# Could add difference between first and last, larger the better, could do some more sophisticated imputing. Chose simply the mode for now\n",
    "# Also skewed for now\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_train['reviews_first'] = pd.to_datetime(feature_train['reviews_first'])\n",
    "reviews_first_mode = feature_train['reviews_first'].mode()[0]\n",
    "feature_train['reviews_first'] = feature_train['reviews_first'].fillna(feature_train['reviews_first'].mode()[0])\n",
    "\n",
    "feature_train['reviews_last'] = pd.to_datetime(feature_train['reviews_last'])\n",
    "reviews_last_mode = feature_train['reviews_last'].mode()[0]\n",
    "feature_train['reviews_last'] = feature_train['reviews_last'].fillna(feature_train['reviews_last'].mode()[0])\n",
    "\n",
    "feature_train['reviews_first_since_scraped'] = (feature_train['property_scraped_at'] -feature_train['reviews_first']).dt.days.astype('int16')\n",
    "feature_train['reviews_last_since_scraped'] =  (feature_train['property_scraped_at'] -feature_train['reviews_last']).dt.days.astype('int16')\n",
    "\n",
    "feature_train = feature_train.drop(['reviews_first'], axis = 1) # Dropping old columns\n",
    "feature_train = feature_train.drop(['reviews_last'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['reviews_first_since_scraped']],axis=1)\n",
    "transformed_train = pd.concat([transformed_train,feature_train['reviews_last_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "8vS4DH7w4klS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_rating\n",
    "reviews_rating_mode = feature_train['reviews_rating'].mode()[0]\n",
    "feature_train['reviews_rating']=feature_train['reviews_rating'].fillna(feature_train['reviews_rating'].mode()[0])\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['reviews_rating']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "-te7JzlM5NqY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reviews_acc\n",
    "reviews_acc_mode = feature_train['reviews_acc'].mode()[0]\n",
    "feature_train['reviews_acc']=feature_train['reviews_acc'].fillna(feature_train['reviews_acc'].mode()[0])\n",
    "\n",
    "transformed_train = pd.concat([transformed_train,feature_train['reviews_acc']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fix column names\n",
    "transformed_train.columns = transformed_train.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: bool)\n"
     ]
    }
   ],
   "source": [
    "nans = transformed_train.isna().any()\n",
    "print(nans.loc[nans==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Avk9qpQ8gylH",
    "outputId": "7c775fdf-c082-4ca1-bb02-8693ff3741de"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m eda\u001b[39m=\u001b[39mAV\u001b[39m.\u001b[39mAutoViz(filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,dfte\u001b[39m=\u001b[39mfeature_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AV' is not defined"
     ]
    }
   ],
   "source": [
    "eda=AV.AutoViz(filename=\"\",dfte=feature_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creation of Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping this would be the same as the word doc table\n",
    "feature_test = feature_test.drop(['property_id','property_space','property_desc','property_neighborhood','property_notes','property_access',\n",
    "                                    \"property_interaction\",\"property_rules\",\"host_location\",\"host_about\",\"host_id\",\"property_sqfeet\"], axis = 1)\n",
    "feature_test = feature_test.drop([\"property_transit\"],axis=1)\n",
    "transformed_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All df to lower case -works\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def toLower(df):\n",
    "    df = df.apply(lambda x: x.str.lower() if x.dtype=='object' else x)\n",
    "    return df\n",
    "\n",
    "toLower = FunctionTransformer(toLower)\n",
    "toLower.fit_transform(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property name: replaced by the word count & new column:missing? - works\n",
    "\n",
    "feature_test['property_name_miss'] = np.where(feature_test['property_name'].isna(), 1, 0)\n",
    "# Should refactor this because if run twice it throws an error\n",
    "feature_test.property_name = feature_test['property_name'].str.split().str.len()\n",
    "feature_test.property_name = feature_test.property_name.fillna(0)\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test.property_name],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,feature_test.property_name_miss],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property summary: new columns - summary_missing & property_summary_count\n",
    "## Missing = 'nan' or one word in summary\n",
    "str_df  = pd.DataFrame()\n",
    "str_df['condition'] = feature_test['property_summary'].str.match(r'\\A[\\w-]+\\Z')\n",
    "\n",
    "feature_test = pd.merge(str_df, feature_test, left_index=True, right_index=True)\n",
    "feature_test['property_summary_miss'] = np.where(feature_test['condition'].isna(), 1, 0)\n",
    "feature_test = feature_test.drop(['condition'], axis = 1)\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test.property_summary_miss],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Property_summary_count: remove numbers, punctuation \n",
    "feature_test['property_summary'] = feature_test['property_summary'].str.replace('\\d+', '')\n",
    "feature_test['property_summary'] = feature_test['property_summary'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "feature_test['property_summary_count'] = feature_test['property_summary'].str.split().str.len()\n",
    "feature_test = feature_test.drop(['property_summary'], axis = 1)\n",
    "feature_test.property_summary_count = feature_test.property_summary_count.fillna(0)\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test.property_summary_count],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_zipcode: replaced with mode\n",
    "\n",
    "feature_test['property_zipcode'] = feature_test['property_zipcode'] .fillna(zipcode_mode)\n",
    "\n",
    "feature_test.loc[feature_test['property_zipcode']=='11 20','property_zipcode']=1120\n",
    "\n",
    "freq_table=feature_test['property_zipcode'].value_counts()\n",
    "\n",
    "#encoding: preserve 11 most frequent categories\n",
    "feature_test.property_zipcode=feature_test.property_zipcode.astype(int)\n",
    "zipcode_cats = pd.get_dummies(feature_test.property_zipcode)\n",
    "sorted_zipcode_cats = zipcode_cats[zipcode_cats.sum().sort_values(ascending=False).index]\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,sorted_zipcode_cats.iloc[:,:10]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_type: regrouped into - apartment, house, other\n",
    "threshold_percent = 3\n",
    "\n",
    "series = pd.value_counts(feature_test['property_type'])\n",
    "mask = (series / series.sum() * 100).lt(threshold_percent)\n",
    "\n",
    "feature_test = feature_test.assign(property_type = np.where(feature_test['property_type'].isin(series[mask].index),'Other', feature_test['property_type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode property_type\n",
    "type_cats = pd.get_dummies(feature_test['property_type'])\n",
    "transformed_test = pd.concat([transformed_test,type_cats],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bathrooms: regroup into 1. None 2. One 3. More than one\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_test['property_bathrooms'] =feature_test['property_bathrooms'].fillna(bathrooms_mode)\n",
    "\n",
    "np.unique(feature_test['property_bathrooms'],return_counts=True)\n",
    "\n",
    "feature_test['property_bathrooms_cat']= 'One'\n",
    "feature_test.loc[(feature_test['property_bathrooms'] < 1) , 'property_bathrooms_cat'] = 'None'\n",
    "feature_test.loc[(feature_test['property_bathrooms'] > 1), 'property_bathrooms_cat'] = 'More than one'\n",
    "\n",
    "feature_test = feature_test.drop(['property_bathrooms'], axis = 1)\n",
    "feature_test['property_bathrooms_cat']\n",
    "\n",
    "bathroom_cats = pd.get_dummies(feature_test['property_bathrooms_cat'])\n",
    "transformed_test = pd.concat([transformed_test,bathroom_cats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bedrooms\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "def NumToCategory(df, column,new_column, missing_value = 0):\n",
    "  df[column] =df[column].fillna(missing_value)\n",
    "\n",
    "  df.loc[(df[column] == 1), new_column] = 'One'\n",
    "  df.loc[(df[column] == 2), new_column] = 'Two'\n",
    "  df.loc[(df[column] == 3), new_column] = 'Three'\n",
    "  df.loc[(df[column] > 3), new_column] = 'More than three'\n",
    "\n",
    "  df = df.drop([column], axis = 1)\n",
    "  return df\n",
    "\n",
    "feature_test = NumToCategory(feature_test, 'property_beds', 'property_beds_cat')\n",
    "feature_test = NumToCategory(feature_test, 'property_bedrooms', 'property_bedrooms_cat')\n",
    "\n",
    "beds_dummies = pd.get_dummies(feature_test['property_beds_cat'])\n",
    "bedrooms_dummies = pd.get_dummies(feature_test['property_bedrooms_cat'])\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,beds_dummies,bedrooms_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bed_type: ok\n",
    "feature_test['property_bed_type'].unique()\n",
    "# room type: ok\n",
    "pd.value_counts(feature_test['property_room_type'])\n",
    "\n",
    "\n",
    "roomtype_cat = pd.get_dummies(feature_test['property_room_type'])\n",
    "transformed_test = pd.concat([transformed_test,roomtype_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_amenities: count the number of amenities provided\n",
    "# remove nans by the mode \n",
    "\n",
    "# reviews_num: Power transform for skeweness \n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import skewtest\n",
    "\n",
    "feature_test['property_amenities'] =  feature_test['property_amenities'].str.split(', ').str.len()\n",
    "feature_test['property_amenities'] = feature_test['property_amenities'].fillna(amenities_mode)\n",
    "\n",
    "def powerTransform(df, column):\n",
    "  col  = np.array( df[column]).reshape(-1, 1)\n",
    "  pt = PowerTransformer(method='yeo-johnson', standardize=True,) \n",
    "  fit = pt.fit(col)\n",
    "  fit = pt.transform(col)\n",
    "  df[column] = fit\n",
    "  return df\n",
    "\n",
    "feature_test = powerTransform(feature_test,'property_amenities')\n",
    "feature_test = powerTransform(feature_test,'reviews_num')\n",
    "\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test.property_amenities],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,feature_test.reviews_num],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_cleanliness\n",
    "# Good: above 5, Bad: below 5, None: average (could be set to \"Missing\", but people who find a property okay usually dont leave reviews, hence, average. Missing might be misleading)\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def reviewRecoding(df, column, new_column):\n",
    "  df[new_column] = df[column].fillna('Average')\n",
    "  df.loc[(df[column] <= 5) , new_column] = 'Bad'\n",
    "  df.loc[(df[column] > 5), new_column] = 'Good'\n",
    "  df = df.drop([column], axis = 1)\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_test = reviewRecoding(feature_test, 'reviews_cleanliness', 'reviews_cleanliness_n')\n",
    "feature_test = reviewRecoding(feature_test, 'reviews_checkin', 'reviews_checkin_n')\n",
    "feature_test = reviewRecoding(feature_test, 'reviews_location', 'reviews_communication_n')\n",
    "feature_test = reviewRecoding(feature_test, 'reviews_communication', 'reviews_communication_n')\n",
    "feature_test = reviewRecoding(feature_test, 'reviews_value', 'reviews_value_n')\n",
    "\n",
    "cleanliness_cat = pd.get_dummies(feature_test['reviews_cleanliness_n'])\n",
    "checkin_cat = pd.get_dummies(feature_test['reviews_checkin_n'])\n",
    "location_cat = pd.get_dummies(feature_test['reviews_communication_n'])\n",
    "communication_cat = pd.get_dummies(feature_test['reviews_communication_n'])\n",
    "value_cat = pd.get_dummies(feature_test['reviews_value_n'])\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,cleanliness_cat],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,checkin_cat],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,location_cat],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,communication_cat],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,value_cat],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_per_month (avg): right skewed - log transform\n",
    "#add 1 to all to avoid log problems\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "feature_test['reviews_per_month'] =feature_test['reviews_per_month'].fillna(reviews_per_month_mode)\n",
    "feature_test['reviews_per_month'] =feature_test['reviews_per_month']+1\n",
    "def reviewsLog(df, feature):\n",
    "  logTr = ColumnTransformer(transformers=[('lg', FunctionTransformer(np.log),[feature])])\n",
    "  log = logTr.fit_transform(df)\n",
    "  df[feature] = log\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_test = reviewsLog(feature_test, 'reviews_per_month')\n",
    "feature_test.reviews_per_month = feature_test.reviews_per_month.fillna(0)\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test.reviews_per_month],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_scraped_at\n",
    "feature_test['property_scraped_at']= pd.to_datetime(feature_test['property_scraped_at'])\n",
    "feature_test['scraped_weekday']=feature_test['property_scraped_at'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode property_scraped_at\n",
    "start_year = 2017\n",
    "days_since_2017 = (feature_test['property_scraped_at'] - pd.Timestamp(str(start_year))).dt.days\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,days_since_2017],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_last_updated\n",
    "# Naturally last_updated is a string :))))))\n",
    "\n",
    "def last_updated_conversion(update_var:str):\n",
    "  # 3 Buckets evenly distributed based on test, 2 for > 3 months, 0 for updated yesterday/today\n",
    "  if \"never\" in update_var:\n",
    "    return \"3 months or more\"\n",
    "  elif \"month\" in update_var:\n",
    "    if int(update_var.split(\" \")[0])>=3:\n",
    "      return \"3 months or more\"\n",
    "    else:\n",
    "      return \"1 week to 3 months\"\n",
    "  elif \"week\" in update_var:\n",
    "    return \"1 week to 3 months\"\n",
    "  else: # This catches yesterday etc. is actually equivalent to \"day\" in update_var\n",
    "    return \"Within days\"\n",
    "\n",
    "feature_test[\"property_last_updated_bucket\"] = [last_updated_conversion(x) for x in feature_test[\"property_last_updated\"]] \n",
    "feature_test = feature_test.drop([\"property_last_updated\"], axis = 1) # Dropping old columns\n",
    "\n",
    "last_updated_cat = pd.get_dummies(feature_test['property_last_updated_bucket'])\n",
    "transformed_test = pd.concat([transformed_test,last_updated_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_since\n",
    "feature_test['host_since']=pd.to_datetime(feature_test['host_since'])\n",
    "feature_test['host_since'] = feature_test['host_since'].fillna(host_since_mean) # Simply imputing with mean, only had 1 NA anyways\n",
    "feature_test['host_since_scraped'] = feature_test['property_scraped_at']-feature_test['host_since']\n",
    "feature_test['host_since_scraped'] = feature_test['host_since_scraped'].dt.days.astype('int16')\n",
    "#feature_test['host_since_scraped'].hist()\n",
    "feature_test = feature_test.drop(['host_since'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['host_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_time\n",
    "# Given 1k NAN decided to add extra missing category as never having received messages might be a signal, otherwise seems fine\n",
    "feature_test['host_response_time']=feature_test['host_response_time'].fillna(value=\"Missing\",inplace=True)\n",
    "#feature_test['host_response_time'].hist()\n",
    "\n",
    "host_response_cat = pd.get_dummies(feature_test['host_response_time'])\n",
    "transformed_test = pd.concat([transformed_test,host_response_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_rate\n",
    "# Impute 100% response rate for never having received a request which is \"fair\"\n",
    "feature_test['host_response_rate']=feature_test['host_response_rate'].fillna(value=100)\n",
    "# Similar to Rating skewness\n",
    "#feature_test['host_response_rate'].hist()\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['host_response_rate']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_nr_listings, host_nr_listings_total\n",
    "# Decided to drop host_nr_listings_total for now as it is basically the same information as host_nr_listings in the testing set,\n",
    "# if one wants to squeeze more information out one could take the difference between the two as an extra feature\n",
    "# Basically everyone only has 1 property\n",
    "if \"host_nr_listings_total\" in feature_test.columns:\n",
    "  feature_test = feature_test.drop(['host_nr_listings_total'], axis = 1)\n",
    "\n",
    "feature_test.loc[(feature_test['host_nr_listings'] <= 1) , 'host_nr_listings_cat'] = 'One or less'\n",
    "feature_test.loc[(feature_test['host_nr_listings'] > 1) & (feature_test['host_nr_listings'] <=3), 'host_nr_listings_cat'] = 'Two to Three'\n",
    "feature_test.loc[(feature_test['host_nr_listings'] > 3), 'host_nr_listings_cat'] = 'More than 3'\n",
    "\n",
    "#feature_test['host_nr_listings_cat'].hist()\n",
    "feature_test = feature_test.drop(['host_nr_listings'], axis = 1) # Dropping old columns\n",
    "\n",
    "nr_listings_cat = pd.get_dummies(feature_test['host_nr_listings_cat'])\n",
    "transformed_test = pd.concat([transformed_test,nr_listings_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_verified\n",
    "# csv sheet including everything that is \"verified\" e.g. email,phone reviews etc.\n",
    "# Same procedure as with property_summary\n",
    "feature_test['host_verified_count'] = feature_test['host_verified'].str.split(\",\").str.len()\n",
    "#feature_test['host_verified_count'].hist()\n",
    "feature_test = feature_test.drop(['host_verified'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['host_verified_count']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_price_covers \n",
    "# Number of people that can live in the property for the price\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#feature_test['booking_price_covers'].hist()\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['booking_price_covers']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_min_nights\n",
    "# No NAs\n",
    "# Choosing to drop anything that requires booking more than 1 month which is only 37 observations. It should be noted that this will lead to us losing\n",
    "# some information on longterm rentals but I think this is preferable, in particular as these might be faulty observations anyways\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#for now: cap at 31\n",
    "feature_test.loc[feature_test[\"booking_max_nights\"] >31, \"booking_max_nights\"] = 31\n",
    "feature_test['booking_min_nights'].hist()\n",
    "transformed_test = pd.concat([transformed_test,feature_test['booking_min_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_max_nights\n",
    "# no NAs\n",
    "# Capped everything above 2 months \n",
    "feature_test.loc[feature_test[\"booking_max_nights\"] >60, \"booking_max_nights\"] = 60\n",
    "#feature_test['booking_max_nights'].hist()\n",
    "transformed_test = pd.concat([transformed_test,feature_test['booking_max_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_cancel_policy\n",
    "# Seems fine\n",
    "#feature_test['booking_cancel_policy'].hist()\n",
    "\n",
    "cancel_cat = pd.get_dummies(feature_test['booking_cancel_policy'])\n",
    "transformed_test = pd.concat([transformed_test,cancel_cat],axis=1)\n",
    "transformed_test['super_strict_30']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_availability_30/60/90/365\n",
    "# No NAs in any of them\n",
    "# Transform availabilities into representing the availability of respective time periods (e.g. 365-90 day availability = availability for last 9 months)\n",
    "# Only execute once\n",
    "\n",
    "feature_test['booking_availability_365'] = feature_test['booking_availability_365']-feature_test['booking_availability_90']\n",
    "feature_test['booking_availability_90'] = feature_test['booking_availability_90'] - feature_test['booking_availability_60']\n",
    "feature_test['booking_availability_60'] = feature_test['booking_availability_60']- feature_test['booking_availability_30']\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['booking_availability_30']],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,feature_test['booking_availability_60']],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,feature_test['booking_availability_90']],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,feature_test['booking_availability_365']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_first, review_last\n",
    "# Could add difference between first and last, larger the better, could do some more sophisticated imputing. Chose simply the mode for now\n",
    "# Also skewed for now\n",
    "feature_test['reviews_first'] = pd.to_datetime(feature_test['reviews_first'])\n",
    "feature_test['reviews_first'] = feature_test['reviews_first'].fillna(reviews_first_mode)\n",
    "\n",
    "feature_test['reviews_last'] = pd.to_datetime(feature_test['reviews_last'])\n",
    "feature_test['reviews_last'] = feature_test['reviews_last'].fillna(reviews_last_mode)\n",
    "\n",
    "feature_test['reviews_first_since_scraped'] = (feature_test['property_scraped_at'] -feature_test['reviews_first']).dt.days.astype('int16')\n",
    "feature_test['reviews_last_since_scraped'] =  (feature_test['property_scraped_at'] -feature_test['reviews_last']).dt.days.astype('int16')\n",
    "\n",
    "feature_test = feature_test.drop(['reviews_first'], axis = 1) # Dropping old columns\n",
    "feature_test = feature_test.drop(['reviews_last'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['reviews_first_since_scraped']],axis=1)\n",
    "transformed_test = pd.concat([transformed_test,feature_test['reviews_last_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_rating\n",
    "feature_test['reviews_rating']=feature_test['reviews_rating'].fillna(reviews_rating_mode)\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['reviews_rating']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_acc\n",
    "feature_test['reviews_acc']=feature_test['reviews_acc'].fillna(reviews_acc_mode)\n",
    "\n",
    "transformed_test = pd.concat([transformed_test,feature_test['reviews_acc']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "transformed_test.columns = transformed_test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = transformed_test.isna().any()\n",
    "print(nans.loc[nans==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(transformed_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(transformed_test.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66605608 0.89550626 0.96936648 0.99684817 0.99773112 0.99842212\n",
      " 0.99908064 0.99955835 0.99971077 0.99982181 0.99992667 0.99996803\n",
      " 0.99997469 0.99997911 0.99998277 0.99998557 0.99998816 0.99998981\n",
      " 0.99999092 0.99999177 0.99999255 0.99999323 0.99999387 0.9999945\n",
      " 0.99999509 0.99999564 0.99999616 0.9999966  0.99999701 0.99999737\n",
      " 0.99999771 0.99999802 0.99999827 0.9999985  0.99999869 0.99999886\n",
      " 0.99999901 0.99999912 0.99999923 0.99999933 0.99999942 0.99999951\n",
      " 0.99999959 0.99999965 0.99999969 0.99999974 0.99999978 0.99999983\n",
      " 0.99999986 0.99999989 0.99999992 0.99999995 0.99999997 0.99999998\n",
      " 0.99999999 0.99999999 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(transformed_train)\n",
    "\n",
    "print(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca4 = PCA(n_components=4)\n",
    "pca4.fit(transformed_train)\n",
    "\n",
    "train_PCA = pca4.transform(transformed_train)\n",
    "test_PCA = pca4.transform(transformed_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create models\n",
    "lr = LinearRegression()\n",
    "\n",
    "#fit the models\n",
    "lr.fit(train_PCA,target_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_pred = lr.predict(test_PCA)\n",
    "\n",
    "mse = mean_squared_error(y_pred,target_test,squared=False)\n",
    "\n",
    "print(\"Mean Squared Error lr: {:.2f}\".format(mse))\n",
    "\n",
    "# Print the model coefficients\n",
    "#print(\"Model coefficients:\", model.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "Q94tMenIaC2x",
    "outputId": "92dc5f72-5c9d-4a65-e897-b0f8145b759c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create models\n",
    "lasso_low = Lasso(alpha=0.5)\n",
    "lasso_mid = Lasso(alpha=1)\n",
    "lasso_large = Lasso(alpha=100)\n",
    "\n",
    "#fit the models\n",
    "lasso_low.fit(transformed_train,target_train)\n",
    "lasso_mid.fit(transformed_train,target_train)\n",
    "lasso_large.fit(transformed_train,target_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_pred_low = lasso_low.predict(transformed_test)\n",
    "y_pred_mid = lasso_mid.predict(transformed_test)\n",
    "y_pred_large = lasso_large.predict(transformed_test)\n",
    "\n",
    "mse_low = mean_squared_error(y_pred_low,target_test,squared=False)\n",
    "mse_mid = mean_squared_error(y_pred_mid,target_test,squared=False)\n",
    "mse_large = mean_squared_error(y_pred_large,target_test,squared=False)\n",
    "\n",
    "print(\"Mean Squared Error lowlasso: {:.2f}\".format(mse_low))\n",
    "print(\"Mean Squared Error midlasso: {:.2f}\".format(mse_mid))\n",
    "print(\"Mean Squared Error largelasso: {:.2f}\".format(mse_large))\n",
    "\n",
    "# Print the model coefficients\n",
    "#print(\"Model coefficients:\", model.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "# Create models\n",
    "poisson = PoissonRegressor()\n",
    "\n",
    "#fit the models\n",
    "poisson.fit(train_PCA,target_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_pred = lr.predict(test_PCA)\n",
    "\n",
    "mse = mean_squared_error(y_pred,target_test,squared=False)\n",
    "\n",
    "#print(\"Mean Squared Error lr: {:.2f}\".format(mse))\n",
    "\n",
    "# Print the model coefficients\n",
    "#print(\"Model coefficients:\", model.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: multi-layer-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Create models\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(75,50),random_state=2023,max_iter=10000)\n",
    "\n",
    "#fit the models\n",
    "mlp.fit(transformed_train,target_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_pred = mlp.predict(transformed_test)\n",
    "\n",
    "mse = mean_squared_error(y_pred,target_test,squared=False)\n",
    "\n",
    "print(\"Mean Squared Error mlp: {:.2f}\".format(mse))\n",
    "\n",
    "# Print the model coefficients\n",
    "#print(\"Model coefficients:\", model.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fit Model on full dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping this would be the same as the word doc table\n",
    "feature_full = feature_full.drop(['property_id','property_space','property_desc','property_neighborhood','property_notes','property_access',\n",
    "                                    \"property_interaction\",\"property_rules\",\"host_location\",\"host_about\",\"host_id\",\"property_sqfeet\"], axis = 1)\n",
    "feature_full = feature_full.drop([\"property_transit\"],axis=1)\n",
    "transformed_full = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All df to lower case -works\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def toLower(df):\n",
    "    df = df.apply(lambda x: x.str.lower() if x.dtype=='object' else x)\n",
    "    return df\n",
    "\n",
    "toLower = FunctionTransformer(toLower)\n",
    "toLower.fit_transform(feature_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property name: replaced by the word count & new column:missing? - works\n",
    "\n",
    "feature_full['property_name_miss'] = np.where(feature_full['property_name'].isna(), 1, 0)\n",
    "# Should refactor this because if run twice it throws an error\n",
    "feature_full.property_name = feature_full['property_name'].str.split().str.len()\n",
    "feature_full.property_name = feature_full.property_name.fillna(0)\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full.property_name],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,feature_full.property_name_miss],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property summary: new columns - summary_missing & property_summary_count\n",
    "## Missing = 'nan' or one word in summary\n",
    "str_df  = pd.DataFrame()\n",
    "str_df['condition'] = feature_full['property_summary'].str.match(r'\\A[\\w-]+\\Z')\n",
    "\n",
    "feature_full = pd.merge(str_df, feature_full, left_index=True, right_index=True)\n",
    "feature_full['property_summary_miss'] = np.where(feature_full['condition'].isna(), 1, 0)\n",
    "feature_full = feature_full.drop(['condition'], axis = 1)\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full.property_summary_miss],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Property_summary_count: remove numbers, punctuation \n",
    "feature_full['property_summary'] = feature_full['property_summary'].str.replace('\\d+', '')\n",
    "feature_full['property_summary'] = feature_full['property_summary'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "feature_full['property_summary_count'] = feature_full['property_summary'].str.split().str.len()\n",
    "feature_full = feature_full.drop(['property_summary'], axis = 1)\n",
    "feature_full.property_summary_count = feature_full.property_summary_count.fillna(0)\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full.property_summary_count],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_zipcode: replaced with mode\n",
    "zipcode_mode=feature_full['property_zipcode'].mode()[0]\n",
    "feature_full['property_zipcode'] = feature_full['property_zipcode'] .fillna(feature_full['property_zipcode'].mode()[0])\n",
    "\n",
    "feature_full.loc[feature_full['property_zipcode']=='11 20','property_zipcode']=1120\n",
    "\n",
    "freq_table=feature_full['property_zipcode'].value_counts()\n",
    "\n",
    "#encoding: preserve 11 most frequent categories\n",
    "feature_full.property_zipcode=feature_full.property_zipcode.astype(int)\n",
    "zipcode_cats = pd.get_dummies(feature_full.property_zipcode)\n",
    "sorted_zipcode_cats = zipcode_cats[zipcode_cats.sum().sort_values(ascending=False).index]\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,sorted_zipcode_cats.iloc[:,:10]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_type: regrouped into - apartment, house, other\n",
    "threshold_percent = 3\n",
    "\n",
    "series = pd.value_counts(feature_full['property_type'])\n",
    "mask = (series / series.sum() * 100).lt(threshold_percent)\n",
    "\n",
    "feature_full = feature_full.assign(property_type = np.where(feature_full['property_type'].isin(series[mask].index),'Other', feature_full['property_type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode property_type\n",
    "type_cats = pd.get_dummies(feature_full['property_type'])\n",
    "transformed_full = pd.concat([transformed_full,type_cats],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bathrooms: regroup into 1. None 2. One 3. More than one\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bathrooms_mode = feature_full['property_bathrooms'].mode()\n",
    "feature_full['property_bathrooms'] =feature_full['property_bathrooms'].fillna(feature_full['property_bathrooms'].mode())\n",
    "\n",
    "np.unique(feature_full['property_bathrooms'],return_counts=True)\n",
    "\n",
    "feature_full['property_bathrooms_cat']= 'One'\n",
    "feature_full.loc[(feature_full['property_bathrooms'] < 1) , 'property_bathrooms_cat'] = 'None'\n",
    "feature_full.loc[(feature_full['property_bathrooms'] > 1), 'property_bathrooms_cat'] = 'More than one'\n",
    "\n",
    "feature_full = feature_full.drop(['property_bathrooms'], axis = 1)\n",
    "feature_full['property_bathrooms_cat']\n",
    "\n",
    "bathroom_cats = pd.get_dummies(feature_full['property_bathrooms_cat'])\n",
    "transformed_full = pd.concat([transformed_full,bathroom_cats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bedrooms\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "def NumToCategory(df, column,new_column, missing_value = 0):\n",
    "  df[column] =df[column].fillna(missing_value)\n",
    "\n",
    "  df.loc[(df[column] == 1), new_column] = 'One'\n",
    "  df.loc[(df[column] == 2), new_column] = 'Two'\n",
    "  df.loc[(df[column] == 3), new_column] = 'Three'\n",
    "  df.loc[(df[column] > 3), new_column] = 'More than three'\n",
    "\n",
    "  df = df.drop([column], axis = 1)\n",
    "  return df\n",
    "\n",
    "feature_full = NumToCategory(feature_full, 'property_beds', 'property_beds_cat')\n",
    "feature_full = NumToCategory(feature_full, 'property_bedrooms', 'property_bedrooms_cat')\n",
    "\n",
    "beds_dummies = pd.get_dummies(feature_full['property_beds_cat'])\n",
    "bedrooms_dummies = pd.get_dummies(feature_full['property_bedrooms_cat'])\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,beds_dummies,bedrooms_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bed_type: ok\n",
    "feature_full['property_bed_type'].unique()\n",
    "# room type: ok\n",
    "pd.value_counts(feature_full['property_room_type'])\n",
    "\n",
    "\n",
    "roomtype_cat = pd.get_dummies(feature_full['property_room_type'])\n",
    "transformed_full = pd.concat([transformed_full,roomtype_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_amenities: count the number of amenities provided\n",
    "# remove nans by the mode \n",
    "\n",
    "# reviews_num: Power transform for skeweness \n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import skewtest\n",
    "\n",
    "\n",
    "feature_full['property_amenities'] =  feature_full['property_amenities'].str.split(', ').str.len()\n",
    "amenities_mode = feature_full['property_amenities'].mode()[0]\n",
    "feature_full['property_amenities'] = feature_full['property_amenities'].fillna(feature_full['property_amenities'].mode()[0])\n",
    "\n",
    "def powerTransform(df, column):\n",
    "  col  = np.array( df[column]).reshape(-1, 1)\n",
    "  pt = PowerTransformer(method='yeo-johnson', standardize=True,) \n",
    "  fit = pt.fit(col)\n",
    "  fit = pt.transform(col)\n",
    "  df[column] = fit\n",
    "  return df\n",
    "\n",
    "feature_full = powerTransform(feature_full,'property_amenities')\n",
    "feature_full = powerTransform(feature_full,'reviews_num')\n",
    "\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full.property_amenities],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,feature_full.reviews_num],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_cleanliness\n",
    "# Good: above 5, Bad: below 5, None: average (could be set to \"Missing\", but people who find a property okay usually dont leave reviews, hence, average. Missing might be misleading)\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def reviewRecoding(df, column, new_column):\n",
    "  df[new_column] = df[column].fillna('Average')\n",
    "  df.loc[(df[column] <= 5) , new_column] = 'Bad'\n",
    "  df.loc[(df[column] > 5), new_column] = 'Good'\n",
    "  df = df.drop([column], axis = 1)\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_full = reviewRecoding(feature_full, 'reviews_cleanliness', 'reviews_cleanliness_n')\n",
    "feature_full = reviewRecoding(feature_full, 'reviews_checkin', 'reviews_checkin_n')\n",
    "feature_full = reviewRecoding(feature_full, 'reviews_location', 'reviews_communication_n')\n",
    "feature_full = reviewRecoding(feature_full, 'reviews_communication', 'reviews_communication_n')\n",
    "feature_full = reviewRecoding(feature_full, 'reviews_value', 'reviews_value_n')\n",
    "\n",
    "cleanliness_cat = pd.get_dummies(feature_full['reviews_cleanliness_n'])\n",
    "checkin_cat = pd.get_dummies(feature_full['reviews_checkin_n'])\n",
    "location_cat = pd.get_dummies(feature_full['reviews_communication_n'])\n",
    "communication_cat = pd.get_dummies(feature_full['reviews_communication_n'])\n",
    "value_cat = pd.get_dummies(feature_full['reviews_value_n'])\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,cleanliness_cat],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,checkin_cat],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,location_cat],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,communication_cat],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,value_cat],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_per_month (avg): right skewed - log transform\n",
    "#add 1 to all to avoid log problems\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "reviews_per_month_mode = feature_full['reviews_per_month'].mode()\n",
    "\n",
    "feature_full['reviews_per_month'] =feature_full['reviews_per_month'].fillna(feature_full['reviews_per_month'].mode())\n",
    "feature_full['reviews_per_month'] =feature_full['reviews_per_month']+1\n",
    "def reviewsLog(df, feature):\n",
    "  logTr = ColumnTransformer(transformers=[('lg', FunctionTransformer(np.log),[feature])])\n",
    "  log = logTr.fit_transform(df)\n",
    "  df[feature] = log\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_full = reviewsLog(feature_full, 'reviews_per_month')\n",
    "feature_full.reviews_per_month = feature_full.reviews_per_month.fillna(0)\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full.reviews_per_month],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_scraped_at\n",
    "feature_full['property_scraped_at']= pd.to_datetime(feature_full['property_scraped_at'])\n",
    "feature_full['scraped_weekday']=feature_full['property_scraped_at'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode property_scraped_at\n",
    "start_year = 2017\n",
    "days_since_2017 = (feature_full['property_scraped_at'] - pd.Timestamp(str(start_year))).dt.days\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,days_since_2017],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_last_updated\n",
    "# Naturally last_updated is a string :))))))\n",
    "\n",
    "def last_updated_conversion(update_var:str):\n",
    "  # 3 Buckets evenly distributed based on full, 2 for > 3 months, 0 for updated yesterday/today\n",
    "  if \"never\" in update_var:\n",
    "    return \"3 months or more\"\n",
    "  elif \"month\" in update_var:\n",
    "    if int(update_var.split(\" \")[0])>=3:\n",
    "      return \"3 months or more\"\n",
    "    else:\n",
    "      return \"1 week to 3 months\"\n",
    "  elif \"week\" in update_var:\n",
    "    return \"1 week to 3 months\"\n",
    "  else: # This catches yesterday etc. is actually equivalent to \"day\" in update_var\n",
    "    return \"Within days\"\n",
    "\n",
    "feature_full[\"property_last_updated_bucket\"] = [last_updated_conversion(x) for x in feature_full[\"property_last_updated\"]] \n",
    "feature_full = feature_full.drop([\"property_last_updated\"], axis = 1) # Dropping old columns\n",
    "\n",
    "last_updated_cat = pd.get_dummies(feature_full['property_last_updated_bucket'])\n",
    "transformed_full = pd.concat([transformed_full,last_updated_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_since\n",
    "feature_full['host_since']=pd.to_datetime(feature_full['host_since'])\n",
    "host_since_mean = feature_full['host_since'].mean()\n",
    "feature_full['host_since'] = feature_full['host_since'].fillna(host_since_mean) # Simply imputing with mean, only had 1 NA anyways\n",
    "feature_full['host_since_scraped'] = feature_full['property_scraped_at']-feature_full['host_since']\n",
    "feature_full['host_since_scraped'] = feature_full['host_since_scraped'].dt.days.astype('int16')\n",
    "#feature_full['host_since_scraped'].hist()\n",
    "feature_full = feature_full.drop(['host_since'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['host_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_time\n",
    "# Given 1k NAN decided to add extra missing category as never having received messages might be a signal, otherwise seems fine\n",
    "feature_full['host_response_time']=feature_full['host_response_time'].fillna(value=\"Missing\",inplace=True)\n",
    "#feature_full['host_response_time'].hist()\n",
    "\n",
    "host_response_cat = pd.get_dummies(feature_full['host_response_time'])\n",
    "transformed_full = pd.concat([transformed_full,host_response_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_rate\n",
    "# Impute 100% response rate for never having received a request which is \"fair\"\n",
    "feature_full['host_response_rate']=feature_full['host_response_rate'].fillna(value=100)\n",
    "# Similar to Rating skewness\n",
    "#feature_full['host_response_rate'].hist()\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['host_response_rate']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_nr_listings, host_nr_listings_total\n",
    "# Decided to drop host_nr_listings_total for now as it is basically the same information as host_nr_listings in the fulling set,\n",
    "# if one wants to squeeze more information out one could take the difference between the two as an extra feature\n",
    "# Basically everyone only has 1 property\n",
    "if \"host_nr_listings_total\" in feature_full.columns:\n",
    "  feature_full = feature_full.drop(['host_nr_listings_total'], axis = 1)\n",
    "\n",
    "feature_full.loc[(feature_full['host_nr_listings'] <= 1) , 'host_nr_listings_cat'] = 'One or less'\n",
    "feature_full.loc[(feature_full['host_nr_listings'] > 1) & (feature_full['host_nr_listings'] <=3), 'host_nr_listings_cat'] = 'Two to Three'\n",
    "feature_full.loc[(feature_full['host_nr_listings'] > 3), 'host_nr_listings_cat'] = 'More than 3'\n",
    "\n",
    "#feature_full['host_nr_listings_cat'].hist()\n",
    "feature_full = feature_full.drop(['host_nr_listings'], axis = 1) # Dropping old columns\n",
    "\n",
    "nr_listings_cat = pd.get_dummies(feature_full['host_nr_listings_cat'])\n",
    "transformed_full = pd.concat([transformed_full,nr_listings_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_verified\n",
    "# csv sheet including everything that is \"verified\" e.g. email,phone reviews etc.\n",
    "# Same procedure as with property_summary\n",
    "feature_full['host_verified_count'] = feature_full['host_verified'].str.split(\",\").str.len()\n",
    "#feature_full['host_verified_count'].hist()\n",
    "feature_full = feature_full.drop(['host_verified'], axis = 1) # Dropping old columns\n",
    "\n",
    "feature_full['host_verified_count'] = feature_full['host_verified_count'].fillna(0)\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['host_verified_count']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_price_covers \n",
    "# Number of people that can live in the property for the price\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#feature_full['booking_price_covers'].hist()\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['booking_price_covers']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_min_nights\n",
    "# No NAs\n",
    "# Choosing to drop anything that requires booking more than 1 month which is only 37 observations. It should be noted that this will lead to us losing\n",
    "# some information on longterm rentals but I think this is preferable, in particular as these might be faulty observations anyways\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#for now: cap at 31\n",
    "feature_full.loc[feature_full[\"booking_max_nights\"] >31, \"booking_max_nights\"] = 31\n",
    "feature_full['booking_min_nights'].hist()\n",
    "transformed_full = pd.concat([transformed_full,feature_full['booking_min_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_max_nights\n",
    "# no NAs\n",
    "# Capped everything above 2 months \n",
    "feature_full.loc[feature_full[\"booking_max_nights\"] >60, \"booking_max_nights\"] = 60\n",
    "#feature_full['booking_max_nights'].hist()\n",
    "transformed_full = pd.concat([transformed_full,feature_full['booking_max_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_cancel_policy\n",
    "# Seems fine\n",
    "#feature_full['booking_cancel_policy'].hist()\n",
    "\n",
    "cancel_cat = pd.get_dummies(feature_full['booking_cancel_policy'])\n",
    "transformed_full = pd.concat([transformed_full,cancel_cat],axis=1)\n",
    "transformed_full['super_strict_30']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_availability_30/60/90/365\n",
    "# No NAs in any of them\n",
    "# Transform availabilities into representing the availability of respective time periods (e.g. 365-90 day availability = availability for last 9 months)\n",
    "# Only execute once\n",
    "\n",
    "feature_full['booking_availability_365'] = feature_full['booking_availability_365']-feature_full['booking_availability_90']\n",
    "feature_full['booking_availability_90'] = feature_full['booking_availability_90'] - feature_full['booking_availability_60']\n",
    "feature_full['booking_availability_60'] = feature_full['booking_availability_60']- feature_full['booking_availability_30']\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['booking_availability_30']],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,feature_full['booking_availability_60']],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,feature_full['booking_availability_90']],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,feature_full['booking_availability_365']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_first, review_last\n",
    "# Could add difference between first and last, larger the better, could do some more sophisticated imputing. Chose simply the mode for now\n",
    "# Also skewed for now\n",
    "feature_full['reviews_first'] = pd.to_datetime(feature_full['reviews_first'])\n",
    "reviews_first_mode = feature_full['reviews_first'].mode()[0]\n",
    "feature_full['reviews_first'] = feature_full['reviews_first'].fillna(feature_full['reviews_first'].mode()[0])\n",
    "\n",
    "feature_full['reviews_last'] = pd.to_datetime(feature_full['reviews_last'])\n",
    "reviews_last_mode = feature_full['reviews_last'].mode()[0]\n",
    "feature_full['reviews_last'] = feature_full['reviews_last'].fillna(feature_full['reviews_last'].mode()[0])\n",
    "\n",
    "feature_full['reviews_first_since_scraped'] = (feature_full['property_scraped_at'] -feature_full['reviews_first']).dt.days.astype('int16')\n",
    "feature_full['reviews_last_since_scraped'] =  (feature_full['property_scraped_at'] -feature_full['reviews_last']).dt.days.astype('int16')\n",
    "\n",
    "feature_full = feature_full.drop(['reviews_first'], axis = 1) # Dropping old columns\n",
    "feature_full = feature_full.drop(['reviews_last'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['reviews_first_since_scraped']],axis=1)\n",
    "transformed_full = pd.concat([transformed_full,feature_full['reviews_last_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_rating\n",
    "reviews_rating_mode = feature_full['reviews_rating'].mode()[0]\n",
    "feature_full['reviews_rating']=feature_full['reviews_rating'].fillna(feature_full['reviews_rating'].mode()[0])\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['reviews_rating']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_acc\n",
    "reviews_acc_mode = feature_full['reviews_acc'].mode()[0]\n",
    "feature_full['reviews_acc']=feature_full['reviews_acc'].fillna(feature_full['reviews_acc'].mode()[0])\n",
    "\n",
    "transformed_full = pd.concat([transformed_full,feature_full['reviews_acc']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "transformed_full.columns = transformed_full.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = transformed_full.isna().any()\n",
    "print(nans.loc[nans==True])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fit best models on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(transformed_full)\n",
    "\n",
    "print(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca4 = PCA(n_components=4)\n",
    "pca4.fit(transformed_full)\n",
    "\n",
    "full_PCA = pca4.transform(transformed_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create models\n",
    "lr = LinearRegression()\n",
    "\n",
    "#fit the models\n",
    "lr.fit(full_PCA,target_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lasso_large = Lasso(alpha=100)\n",
    "lasso_large.fit(transformed_full,target_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Create models\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(75,50),random_state=2023,max_iter=10000)\n",
    "\n",
    "#fit the models\n",
    "mlp.fit(transformed_full,target_price)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Final Prediction Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Final Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test data sets (from GitHub, no need to add it manually)\n",
    "filepath = \"https://raw.githubusercontent.com/AnastasiaDv491/AA-datasets/main/test.csv\"\n",
    "\n",
    "feature_val = pd.read_csv(filepath)\n",
    "feature_val.head()\n",
    "\n",
    "ids = feature_val.property_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transform Final Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping this would be the same as the word doc table\n",
    "feature_val = feature_val.drop(['property_id','property_space','property_desc','property_neighborhood','property_notes','property_access',\n",
    "                                    \"property_interaction\",\"property_rules\",\"host_location\",\"host_about\",\"host_id\",\"property_sqfeet\"], axis = 1)\n",
    "feature_val = feature_val.drop([\"property_transit\"],axis=1)\n",
    "transformed_val = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All df to lower case -works\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def toLower(df):\n",
    "    df = df.apply(lambda x: x.str.lower() if x.dtype=='object' else x)\n",
    "    return df\n",
    "\n",
    "toLower = FunctionTransformer(toLower)\n",
    "toLower.fit_transform(feature_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property name: replaced by the word count & new column:missing? - works\n",
    "\n",
    "feature_val['property_name_miss'] = np.where(feature_val['property_name'].isna(), 1, 0)\n",
    "# Should refactor this because if run twice it throws an error\n",
    "feature_val.property_name = feature_val['property_name'].str.split().str.len()\n",
    "feature_val.property_name = feature_val.property_name.fillna(0)\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val.property_name],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,feature_val.property_name_miss],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Property summary: new columns - summary_missing & property_summary_count\n",
    "## Missing = 'nan' or one word in summary\n",
    "str_df  = pd.DataFrame()\n",
    "str_df['condition'] = feature_val['property_summary'].str.match(r'\\A[\\w-]+\\Z')\n",
    "\n",
    "feature_val = pd.merge(str_df, feature_val, left_index=True, right_index=True)\n",
    "feature_val['property_summary_miss'] = np.where(feature_val['condition'].isna(), 1, 0)\n",
    "feature_val = feature_val.drop(['condition'], axis = 1)\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val.property_summary_miss],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Property_summary_count: remove numbers, punctuation \n",
    "feature_val['property_summary'] = feature_val['property_summary'].str.replace('\\d+', '')\n",
    "feature_val['property_summary'] = feature_val['property_summary'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "feature_val['property_summary_count'] = feature_val['property_summary'].str.split().str.len()\n",
    "feature_val = feature_val.drop(['property_summary'], axis = 1)\n",
    "feature_val.property_summary_count = feature_val.property_summary_count.fillna(0)\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val.property_summary_count],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_zipcode: replaced with mode\n",
    "feature_val['property_zipcode'] = feature_val['property_zipcode'] .fillna(zipcode_mode)\n",
    "\n",
    "feature_val.loc[feature_val['property_zipcode']=='11 20','property_zipcode']=1120\n",
    "\n",
    "freq_table=feature_val['property_zipcode'].value_counts()\n",
    "\n",
    "#encoding: preserve 11 most frequent categories\n",
    "feature_val.property_zipcode=feature_val.property_zipcode.astype(int)\n",
    "zipcode_cats = pd.get_dummies(feature_val.property_zipcode)\n",
    "\n",
    "zipcode_cats.columns\n",
    "sorted_zipcode_cats = zipcode_cats.loc[:,[1000, 1050, 1060, 2000, 1030,1040, 1190, 2018, 1180, 1070]]\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,sorted_zipcode_cats.iloc[:,:10]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_type: regrouped into - apartment, house, other\n",
    "threshold_percent = 3\n",
    "\n",
    "series = pd.value_counts(feature_val['property_type'])\n",
    "mask = (series / series.sum() * 100).lt(threshold_percent)\n",
    "\n",
    "feature_val = feature_val.assign(property_type = np.where(feature_val['property_type'].isin(series[mask].index),'Other', feature_val['property_type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode property_type\n",
    "type_cats = pd.get_dummies(feature_val['property_type'])\n",
    "transformed_val = pd.concat([transformed_val,type_cats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bathrooms: regroup into 1. None 2. One 3. More than one\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_val['property_bathrooms'] =feature_val['property_bathrooms'].fillna(bathrooms_mode)\n",
    "\n",
    "np.unique(feature_val['property_bathrooms'],return_counts=True)\n",
    "\n",
    "feature_val['property_bathrooms_cat']= 'One'\n",
    "feature_val.loc[(feature_val['property_bathrooms'] < 1) , 'property_bathrooms_cat'] = 'None'\n",
    "feature_val.loc[(feature_val['property_bathrooms'] > 1), 'property_bathrooms_cat'] = 'More than one'\n",
    "\n",
    "feature_val = feature_val.drop(['property_bathrooms'], axis = 1)\n",
    "feature_val['property_bathrooms_cat']\n",
    "\n",
    "bathroom_cats = pd.get_dummies(feature_val['property_bathrooms_cat'])\n",
    "transformed_val = pd.concat([transformed_val,bathroom_cats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bedrooms\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "def NumToCategory(df, column,new_column, missing_value = 0):\n",
    "  df[column] =df[column].fillna(missing_value)\n",
    "\n",
    "  df.loc[(df[column] == 1), new_column] = 'One'\n",
    "  df.loc[(df[column] == 2), new_column] = 'Two'\n",
    "  df.loc[(df[column] == 3), new_column] = 'Three'\n",
    "  df.loc[(df[column] > 3), new_column] = 'More than three'\n",
    "\n",
    "  df = df.drop([column], axis = 1)\n",
    "  return df\n",
    "\n",
    "feature_val = NumToCategory(feature_val, 'property_beds', 'property_beds_cat')\n",
    "feature_val = NumToCategory(feature_val, 'property_bedrooms', 'property_bedrooms_cat')\n",
    "\n",
    "beds_dummies = pd.get_dummies(feature_val['property_beds_cat'])\n",
    "bedrooms_dummies = pd.get_dummies(feature_val['property_bedrooms_cat'])\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,beds_dummies,bedrooms_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bed_type: ok\n",
    "feature_val['property_bed_type'].unique()\n",
    "# room type: ok\n",
    "pd.value_counts(feature_val['property_room_type'])\n",
    "\n",
    "\n",
    "roomtype_cat = pd.get_dummies(feature_val['property_room_type'])\n",
    "transformed_val = pd.concat([transformed_val,roomtype_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_amenities: count the number of amenities provided\n",
    "# remove nans by the mode \n",
    "\n",
    "# reviews_num: Power transform for skeweness \n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import skewtest\n",
    "\n",
    "\n",
    "feature_val['property_amenities'] =  feature_val['property_amenities'].str.split(', ').str.len()\n",
    "feature_val['property_amenities'] = feature_val['property_amenities'].fillna(amenities_mode)\n",
    "\n",
    "def powerTransform(df, column):\n",
    "  col  = np.array( df[column]).reshape(-1, 1)\n",
    "  pt = PowerTransformer(method='yeo-johnson', standardize=True,) \n",
    "  fit = pt.fit(col)\n",
    "  fit = pt.transform(col)\n",
    "  df[column] = fit\n",
    "  return df\n",
    "\n",
    "feature_val = powerTransform(feature_val,'property_amenities')\n",
    "feature_val = powerTransform(feature_val,'reviews_num')\n",
    "\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val.property_amenities],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,feature_val.reviews_num],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_cleanliness\n",
    "# Good: above 5, Bad: below 5, None: average (could be set to \"Missing\", but people who find a property okay usually dont leave reviews, hence, average. Missing might be misleading)\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def reviewRecoding(df, column, new_column):\n",
    "  df[new_column] = df[column].fillna('Average')\n",
    "  df.loc[(df[column] <= 5) , new_column] = 'Bad'\n",
    "  df.loc[(df[column] > 5), new_column] = 'Good'\n",
    "  df = df.drop([column], axis = 1)\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_val = reviewRecoding(feature_val, 'reviews_cleanliness', 'reviews_cleanliness_n')\n",
    "feature_val = reviewRecoding(feature_val, 'reviews_checkin', 'reviews_checkin_n')\n",
    "feature_val = reviewRecoding(feature_val, 'reviews_location', 'reviews_communication_n')\n",
    "feature_val = reviewRecoding(feature_val, 'reviews_communication', 'reviews_communication_n')\n",
    "feature_val = reviewRecoding(feature_val, 'reviews_value', 'reviews_value_n')\n",
    "\n",
    "cleanliness_cat = pd.get_dummies(feature_val['reviews_cleanliness_n'])\n",
    "checkin_cat = pd.get_dummies(feature_val['reviews_checkin_n'])\n",
    "location_cat = pd.get_dummies(feature_val['reviews_communication_n'])\n",
    "communication_cat = pd.get_dummies(feature_val['reviews_communication_n'])\n",
    "value_cat = pd.get_dummies(feature_val['reviews_value_n'])\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,cleanliness_cat],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,checkin_cat],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,location_cat],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,communication_cat],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,value_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_per_month (avg): right skewed - log transform\n",
    "#add 1 to all to avoid log problems\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "feature_val['reviews_per_month'] =feature_val['reviews_per_month'].fillna(reviews_per_month_mode)\n",
    "feature_val['reviews_per_month'] =feature_val['reviews_per_month']+1\n",
    "def reviewsLog(df, feature):\n",
    "  logTr = ColumnTransformer(transformers=[('lg', FunctionTransformer(np.log),[feature])])\n",
    "  log = logTr.fit_transform(df)\n",
    "  df[feature] = log\n",
    "\n",
    "  return df\n",
    "\n",
    "feature_val = reviewsLog(feature_val, 'reviews_per_month')\n",
    "feature_val.reviews_per_month = feature_val.reviews_per_month.fillna(0)\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val.reviews_per_month],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_scraped_at\n",
    "feature_val['property_scraped_at']= pd.to_datetime(feature_val['property_scraped_at'])\n",
    "feature_val['scraped_weekday']=feature_val['property_scraped_at'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode property_scraped_at\n",
    "start_year = 2017\n",
    "days_since_2017 = (feature_val['property_scraped_at'] - pd.Timestamp(str(start_year))).dt.days\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,days_since_2017],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_last_updated\n",
    "# Naturally last_updated is a string :))))))\n",
    "\n",
    "def last_updated_conversion(update_var:str):\n",
    "  # 3 Buckets evenly distributed based on val, 2 for > 3 months, 0 for updated yesterday/today\n",
    "  if \"never\" in update_var:\n",
    "    return \"3 months or more\"\n",
    "  elif \"month\" in update_var:\n",
    "    if int(update_var.split(\" \")[0])>=3:\n",
    "      return \"3 months or more\"\n",
    "    else:\n",
    "      return \"1 week to 3 months\"\n",
    "  elif \"week\" in update_var:\n",
    "    return \"1 week to 3 months\"\n",
    "  else: # This catches yesterday etc. is actually equivalent to \"day\" in update_var\n",
    "    return \"Within days\"\n",
    "\n",
    "feature_val[\"property_last_updated_bucket\"] = [last_updated_conversion(x) for x in feature_val[\"property_last_updated\"]] \n",
    "feature_val = feature_val.drop([\"property_last_updated\"], axis = 1) # Dropping old columns\n",
    "\n",
    "last_updated_cat = pd.get_dummies(feature_val['property_last_updated_bucket'])\n",
    "transformed_val = pd.concat([transformed_val,last_updated_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_since\n",
    "feature_val['host_since']=pd.to_datetime(feature_val['host_since'])\n",
    "feature_val['host_since'] = feature_val['host_since'].fillna(host_since_mean) # Simply imputing with mean, only had 1 NA anyways\n",
    "feature_val['host_since_scraped'] = feature_val['property_scraped_at']-feature_val['host_since']\n",
    "feature_val['host_since_scraped'] = feature_val['host_since_scraped'].dt.days.astype('int16')\n",
    "#feature_val['host_since_scraped'].hist()\n",
    "feature_val = feature_val.drop(['host_since'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['host_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_time\n",
    "# Given 1k NAN decided to add extra missing category as never having received messages might be a signal, otherwise seems fine\n",
    "feature_val['host_response_time']=feature_val['host_response_time'].fillna(value=\"Missing\",inplace=True)\n",
    "#feature_val['host_response_time'].hist()\n",
    "\n",
    "host_response_cat = pd.get_dummies(feature_val['host_response_time'])\n",
    "transformed_val = pd.concat([transformed_val,host_response_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_response_rate\n",
    "# Impute 100% response rate for never having received a request which is \"fair\"\n",
    "feature_val['host_response_rate']=feature_val['host_response_rate'].fillna(value=100)\n",
    "# Similar to Rating skewness\n",
    "#feature_val['host_response_rate'].hist()\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['host_response_rate']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_nr_listings, host_nr_listings_total\n",
    "# Decided to drop host_nr_listings_total for now as it is basically the same information as host_nr_listings in the valing set,\n",
    "# if one wants to squeeze more information out one could take the difference between the two as an extra feature\n",
    "# Basically everyone only has 1 property\n",
    "if \"host_nr_listings_total\" in feature_val.columns:\n",
    "  feature_val = feature_val.drop(['host_nr_listings_total'], axis = 1)\n",
    "\n",
    "feature_val.loc[(feature_val['host_nr_listings'] <= 1) , 'host_nr_listings_cat'] = 'One or less'\n",
    "feature_val.loc[(feature_val['host_nr_listings'] > 1) & (feature_val['host_nr_listings'] <=3), 'host_nr_listings_cat'] = 'Two to Three'\n",
    "feature_val.loc[(feature_val['host_nr_listings'] > 3), 'host_nr_listings_cat'] = 'More than 3'\n",
    "\n",
    "#feature_val['host_nr_listings_cat'].hist()\n",
    "feature_val = feature_val.drop(['host_nr_listings'], axis = 1) # Dropping old columns\n",
    "\n",
    "nr_listings_cat = pd.get_dummies(feature_val['host_nr_listings_cat'])\n",
    "transformed_val = pd.concat([transformed_val,nr_listings_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_verified\n",
    "# csv sheet including everything that is \"verified\" e.g. email,phone reviews etc.\n",
    "# Same procedure as with property_summary\n",
    "feature_val['host_verified_count'] = feature_val['host_verified'].str.split(\",\").str.len()\n",
    "#feature_val['host_verified_count'].hist()\n",
    "feature_val = feature_val.drop(['host_verified'], axis = 1) # Dropping old columns\n",
    "\n",
    "feature_val['host_verified_count'] = feature_val['host_verified_count'].fillna(0)\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['host_verified_count']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_price_covers \n",
    "# Number of people that can live in the property for the price\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#feature_val['booking_price_covers'].hist()\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['booking_price_covers']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_min_nights\n",
    "# No NAs\n",
    "# Choosing to drop anything that requires booking more than 1 month which is only 37 observations. It should be noted that this will lead to us losing\n",
    "# some information on longterm rentals but I think this is preferable, in particular as these might be faulty observations anyways\n",
    "# Again similar to raitings etc. 1 very large category and then everything else. Tempted to code as 0/1\n",
    "\n",
    "#for now: cap at 31\n",
    "feature_val.loc[feature_val[\"booking_max_nights\"] >31, \"booking_max_nights\"] = 31\n",
    "feature_val['booking_min_nights'].hist()\n",
    "transformed_val = pd.concat([transformed_val,feature_val['booking_min_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_max_nights\n",
    "# no NAs\n",
    "# Capped everything above 2 months \n",
    "feature_val.loc[feature_val[\"booking_max_nights\"] >60, \"booking_max_nights\"] = 60\n",
    "#feature_val['booking_max_nights'].hist()\n",
    "transformed_val = pd.concat([transformed_val,feature_val['booking_max_nights']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_cancel_policy\n",
    "# Seems fine\n",
    "#feature_val['booking_cancel_policy'].hist()\n",
    "\n",
    "cancel_cat = pd.get_dummies(feature_val['booking_cancel_policy'])\n",
    "transformed_val = pd.concat([transformed_val,cancel_cat],axis=1)\n",
    "transformed_val['super_strict_30']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# booking_availability_30/60/90/365\n",
    "# No NAs in any of them\n",
    "# Transform availabilities into representing the availability of respective time periods (e.g. 365-90 day availability = availability for last 9 months)\n",
    "# Only execute once\n",
    "\n",
    "feature_val['booking_availability_365'] = feature_val['booking_availability_365']-feature_val['booking_availability_90']\n",
    "feature_val['booking_availability_90'] = feature_val['booking_availability_90'] - feature_val['booking_availability_60']\n",
    "feature_val['booking_availability_60'] = feature_val['booking_availability_60']- feature_val['booking_availability_30']\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['booking_availability_30']],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,feature_val['booking_availability_60']],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,feature_val['booking_availability_90']],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,feature_val['booking_availability_365']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_first, review_last\n",
    "# Could add difference between first and last, larger the better, could do some more sophisticated imputing. Chose simply the mode for now\n",
    "# Also skewed for now\n",
    "feature_val['reviews_first'] = pd.to_datetime(feature_val['reviews_first'])\n",
    "feature_val['reviews_first'] = feature_val['reviews_first'].fillna(reviews_first_mode)\n",
    "\n",
    "feature_val['reviews_last'] = pd.to_datetime(feature_val['reviews_last'])\n",
    "feature_val['reviews_last'] = feature_val['reviews_last'].fillna(reviews_last_mode)\n",
    "\n",
    "feature_val['reviews_first_since_scraped'] = (feature_val['property_scraped_at'] -feature_val['reviews_first']).dt.days.astype('int16')\n",
    "feature_val['reviews_last_since_scraped'] =  (feature_val['property_scraped_at'] -feature_val['reviews_last']).dt.days.astype('int16')\n",
    "\n",
    "feature_val = feature_val.drop(['reviews_first'], axis = 1) # Dropping old columns\n",
    "feature_val = feature_val.drop(['reviews_last'], axis = 1) # Dropping old columns\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['reviews_first_since_scraped']],axis=1)\n",
    "transformed_val = pd.concat([transformed_val,feature_val['reviews_last_since_scraped']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_rating\n",
    "feature_val['reviews_rating']=feature_val['reviews_rating'].fillna(reviews_rating_mode)\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['reviews_rating']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_acc\n",
    "feature_val['reviews_acc']=feature_val['reviews_acc'].fillna(reviews_acc_mode)\n",
    "\n",
    "transformed_val = pd.concat([transformed_val,feature_val['reviews_acc']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix column names\n",
    "transformed_val.columns = transformed_val.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = transformed_val.isna().any()\n",
    "print(nans.loc[nans==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_val.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_PCA = pca4.transform(transformed_val)\n",
    "\n",
    "price_pred_lr = lr.predict(val_PCA)\n",
    "\n",
    "#print(price_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to csv\n",
    "\n",
    "price_pred_lr=price_pred_lr.flatten('C')\n",
    "price_pred_lr=price_pred_lr.round(decimals=4)\n",
    "df=pd.DataFrame({'ID':ids,'PRED':price_pred_lr})\n",
    "df\n",
    "df.to_csv('price_pred_lr.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pred_lasso = lasso_large.predict(transformed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pred_lasso=price_pred_lasso.flatten('C')\n",
    "price_pred_lasso=price_pred_lasso.round(decimals=4)\n",
    "df=pd.DataFrame({'ID':ids,'PRED':price_pred_lasso})\n",
    "df\n",
    "df.to_csv('price_pred_lasso.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pred_mlp = mlp.predict(transformed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pred_mlp=price_pred_mlp.flatten('C')\n",
    "price_pred_mlp=price_pred_mlp.round(decimals=4)\n",
    "df=pd.DataFrame({'ID':ids,'PRED':price_pred_mlp})\n",
    "df\n",
    "df.to_csv('price_pred_mlp.csv',index=False,sep=',')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0SLjt5KOjT0n",
    "Puz6mw2NRBz7",
    "qszpOlYr28v-",
    "liCQnLyeJBHV"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
